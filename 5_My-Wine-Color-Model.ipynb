{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code was provided to me during my data analytics course. I swapped out the content to reflect my vision for predicting wine color.\n",
    "\n",
    "For this example I used the wine quality data set: [wine dataset] (https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/), which is about the quality of red and white wine.\n",
    "\n",
    "From UCI Machine Learning:\n",
    "The two datasets are related to red and white variants of the Portuguese \"Vinho Verde\" wine.\n",
    "\n",
    "I manually combined the two data sets into one and used it throughout this project. The data set consists of over 6,000 combines samples of white and red wine. 13 features were measured from each sample: fixed acidity, volatile acidity, citric acide, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, pH, sulphates, alcohol, quality, and color. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = pd.read_csv(\"data/winedata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "\n",
       "   alcohol  quality  color  \n",
       "0      8.8        6  white  \n",
       "1      9.5        6  white  \n",
       "2     10.1        6  white  \n",
       "3      9.9        6  white  \n",
       "4      9.9        6  white  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
       "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
       "       'pH', 'sulphates', 'alcohol', 'quality', 'color'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at the column headings\n",
    "\n",
    "wine.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model is going to predict the color of the wine.\n",
    "# drop the color column from x and gave it to y\n",
    "\n",
    "X = wine.drop('color',axis=1)\n",
    "y = wine['color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['white', 'red'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# discover the unique entries in the color column\n",
    "\n",
    "wine['color'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use LabelBinarizer to change white and red to 1 and 0\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "encoder = LabelBinarizer()\n",
    "y = encoder.fit_transform(y)\n",
    "\n",
    "# view the transformation of the strings\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and testing data before scaling\n",
    "# here the test data is 20% of a full data set\n",
    "# random state is often set to 42:\n",
    "#https://www.independent.co.uk/life-style/history/42-answer-life-universe-and-everything-2205734.html\n",
    "# the random_state will be removed in the production version\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the most common scalers are MinMaxScaler and StandardScaler\n",
    "\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit\n",
    "\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform\n",
    "\n",
    "scaled_X_train = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "\n",
    "### Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=12,activation='relu',input_shape=[12,]))\n",
    "\n",
    "# Last layer for multi-class classification of 2 colors\n",
    "model.add(Dense(units=2,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5197 samples, validate on 1300 samples\n",
      "Epoch 1/300\n",
      "5197/5197 [==============================] - 0s 96us/sample - loss: 0.5677 - accuracy: 0.7514 - val_loss: 0.4943 - val_accuracy: 0.7638\n",
      "Epoch 2/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.4482 - accuracy: 0.7514 - val_loss: 0.3638 - val_accuracy: 0.7638\n",
      "Epoch 3/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.2742 - accuracy: 0.8947 - val_loss: 0.2072 - val_accuracy: 0.9508\n",
      "Epoch 4/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.1672 - accuracy: 0.9679 - val_loss: 0.1389 - val_accuracy: 0.9746\n",
      "Epoch 5/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.1203 - accuracy: 0.9761 - val_loss: 0.1064 - val_accuracy: 0.9792\n",
      "Epoch 6/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0974 - accuracy: 0.9786 - val_loss: 0.0879 - val_accuracy: 0.9800\n",
      "Epoch 7/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0842 - accuracy: 0.9796 - val_loss: 0.0764 - val_accuracy: 0.9823\n",
      "Epoch 8/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0760 - accuracy: 0.9817 - val_loss: 0.0685 - val_accuracy: 0.9831\n",
      "Epoch 9/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0704 - accuracy: 0.9821 - val_loss: 0.0629 - val_accuracy: 0.9831\n",
      "Epoch 10/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0658 - accuracy: 0.9840 - val_loss: 0.0577 - val_accuracy: 0.9838\n",
      "Epoch 11/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0620 - accuracy: 0.9854 - val_loss: 0.0539 - val_accuracy: 0.9846\n",
      "Epoch 12/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0593 - accuracy: 0.9858 - val_loss: 0.0507 - val_accuracy: 0.9846\n",
      "Epoch 13/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0567 - accuracy: 0.9869 - val_loss: 0.0480 - val_accuracy: 0.9869\n",
      "Epoch 14/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0549 - accuracy: 0.9867 - val_loss: 0.0456 - val_accuracy: 0.9869\n",
      "Epoch 15/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0534 - accuracy: 0.9881 - val_loss: 0.0448 - val_accuracy: 0.9885\n",
      "Epoch 16/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0520 - accuracy: 0.9885 - val_loss: 0.0424 - val_accuracy: 0.9885\n",
      "Epoch 17/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0507 - accuracy: 0.9886 - val_loss: 0.0429 - val_accuracy: 0.9892\n",
      "Epoch 18/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0499 - accuracy: 0.9890 - val_loss: 0.0399 - val_accuracy: 0.9908\n",
      "Epoch 19/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0492 - accuracy: 0.9890 - val_loss: 0.0389 - val_accuracy: 0.9908\n",
      "Epoch 20/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0482 - accuracy: 0.9886 - val_loss: 0.0383 - val_accuracy: 0.9923\n",
      "Epoch 21/300\n",
      "5197/5197 [==============================] - 0s 37us/sample - loss: 0.0474 - accuracy: 0.9885 - val_loss: 0.0373 - val_accuracy: 0.9908\n",
      "Epoch 22/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0467 - accuracy: 0.9892 - val_loss: 0.0367 - val_accuracy: 0.9923\n",
      "Epoch 23/300\n",
      "5197/5197 [==============================] - 0s 37us/sample - loss: 0.0459 - accuracy: 0.9904 - val_loss: 0.0376 - val_accuracy: 0.9908\n",
      "Epoch 24/300\n",
      "5197/5197 [==============================] - 0s 33us/sample - loss: 0.0452 - accuracy: 0.9890 - val_loss: 0.0356 - val_accuracy: 0.9923\n",
      "Epoch 25/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0451 - accuracy: 0.9898 - val_loss: 0.0357 - val_accuracy: 0.9923\n",
      "Epoch 26/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0444 - accuracy: 0.9892 - val_loss: 0.0344 - val_accuracy: 0.9923\n",
      "Epoch 27/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0437 - accuracy: 0.9904 - val_loss: 0.0339 - val_accuracy: 0.9923\n",
      "Epoch 28/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0433 - accuracy: 0.9908 - val_loss: 0.0335 - val_accuracy: 0.9931\n",
      "Epoch 29/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0428 - accuracy: 0.9906 - val_loss: 0.0329 - val_accuracy: 0.9923\n",
      "Epoch 30/300\n",
      "5197/5197 [==============================] - 0s 37us/sample - loss: 0.0423 - accuracy: 0.9911 - val_loss: 0.0344 - val_accuracy: 0.9923\n",
      "Epoch 31/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0422 - accuracy: 0.9904 - val_loss: 0.0321 - val_accuracy: 0.9923\n",
      "Epoch 32/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0415 - accuracy: 0.9908 - val_loss: 0.0317 - val_accuracy: 0.9923\n",
      "Epoch 33/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0412 - accuracy: 0.9911 - val_loss: 0.0322 - val_accuracy: 0.9923\n",
      "Epoch 34/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0409 - accuracy: 0.9917 - val_loss: 0.0320 - val_accuracy: 0.9915\n",
      "Epoch 35/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0406 - accuracy: 0.9915 - val_loss: 0.0310 - val_accuracy: 0.9938\n",
      "Epoch 36/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0401 - accuracy: 0.9917 - val_loss: 0.0303 - val_accuracy: 0.9938\n",
      "Epoch 37/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0398 - accuracy: 0.9927 - val_loss: 0.0302 - val_accuracy: 0.9931\n",
      "Epoch 38/300\n",
      "5197/5197 [==============================] - 0s 37us/sample - loss: 0.0392 - accuracy: 0.9915 - val_loss: 0.0303 - val_accuracy: 0.9915\n",
      "Epoch 39/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0393 - accuracy: 0.9925 - val_loss: 0.0295 - val_accuracy: 0.9938\n",
      "Epoch 40/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0388 - accuracy: 0.9913 - val_loss: 0.0293 - val_accuracy: 0.9954\n",
      "Epoch 41/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0385 - accuracy: 0.9923 - val_loss: 0.0290 - val_accuracy: 0.9946\n",
      "Epoch 42/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0382 - accuracy: 0.9929 - val_loss: 0.0288 - val_accuracy: 0.9946\n",
      "Epoch 43/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0382 - accuracy: 0.9927 - val_loss: 0.0286 - val_accuracy: 0.9954\n",
      "Epoch 44/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0376 - accuracy: 0.9933 - val_loss: 0.0283 - val_accuracy: 0.9954\n",
      "Epoch 45/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0374 - accuracy: 0.9938 - val_loss: 0.0282 - val_accuracy: 0.9938\n",
      "Epoch 46/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0371 - accuracy: 0.9933 - val_loss: 0.0284 - val_accuracy: 0.9923\n",
      "Epoch 47/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0369 - accuracy: 0.9938 - val_loss: 0.0284 - val_accuracy: 0.9915\n",
      "Epoch 48/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0373 - accuracy: 0.9937 - val_loss: 0.0277 - val_accuracy: 0.9931\n",
      "Epoch 49/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0366 - accuracy: 0.9940 - val_loss: 0.0278 - val_accuracy: 0.9923\n",
      "Epoch 50/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0363 - accuracy: 0.9940 - val_loss: 0.0271 - val_accuracy: 0.9962\n",
      "Epoch 51/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0360 - accuracy: 0.9942 - val_loss: 0.0269 - val_accuracy: 0.9946\n",
      "Epoch 52/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0358 - accuracy: 0.9940 - val_loss: 0.0267 - val_accuracy: 0.9946\n",
      "Epoch 53/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0358 - accuracy: 0.9944 - val_loss: 0.0266 - val_accuracy: 0.9962\n",
      "Epoch 54/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0352 - accuracy: 0.9942 - val_loss: 0.0264 - val_accuracy: 0.9946\n",
      "Epoch 55/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0353 - accuracy: 0.9940 - val_loss: 0.0269 - val_accuracy: 0.9938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0349 - accuracy: 0.9938 - val_loss: 0.0260 - val_accuracy: 0.9946\n",
      "Epoch 57/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0345 - accuracy: 0.9938 - val_loss: 0.0267 - val_accuracy: 0.9938\n",
      "Epoch 58/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0349 - accuracy: 0.9942 - val_loss: 0.0256 - val_accuracy: 0.9962\n",
      "Epoch 59/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0343 - accuracy: 0.9944 - val_loss: 0.0255 - val_accuracy: 0.9954\n",
      "Epoch 60/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0343 - accuracy: 0.9944 - val_loss: 0.0253 - val_accuracy: 0.9954\n",
      "Epoch 61/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0338 - accuracy: 0.9944 - val_loss: 0.0255 - val_accuracy: 0.9954\n",
      "Epoch 62/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0338 - accuracy: 0.9942 - val_loss: 0.0255 - val_accuracy: 0.9946\n",
      "Epoch 63/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0340 - accuracy: 0.9944 - val_loss: 0.0250 - val_accuracy: 0.9954\n",
      "Epoch 64/300\n",
      "5197/5197 [==============================] - 0s 33us/sample - loss: 0.0334 - accuracy: 0.9944 - val_loss: 0.0255 - val_accuracy: 0.9938\n",
      "Epoch 65/300\n",
      "5197/5197 [==============================] - ETA: 0s - loss: 0.0356 - accuracy: 0.99 - 0s 34us/sample - loss: 0.0332 - accuracy: 0.9944 - val_loss: 0.0249 - val_accuracy: 0.9954\n",
      "Epoch 66/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0331 - accuracy: 0.9946 - val_loss: 0.0244 - val_accuracy: 0.9962\n",
      "Epoch 67/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0330 - accuracy: 0.9942 - val_loss: 0.0261 - val_accuracy: 0.9931\n",
      "Epoch 68/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0328 - accuracy: 0.9948 - val_loss: 0.0243 - val_accuracy: 0.9954\n",
      "Epoch 69/300\n",
      "5197/5197 [==============================] - 0s 38us/sample - loss: 0.0324 - accuracy: 0.9940 - val_loss: 0.0244 - val_accuracy: 0.9954\n",
      "Epoch 70/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0322 - accuracy: 0.9952 - val_loss: 0.0239 - val_accuracy: 0.9962\n",
      "Epoch 71/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0323 - accuracy: 0.9946 - val_loss: 0.0238 - val_accuracy: 0.9962\n",
      "Epoch 72/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0321 - accuracy: 0.9946 - val_loss: 0.0236 - val_accuracy: 0.9954\n",
      "Epoch 73/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0315 - accuracy: 0.9948 - val_loss: 0.0251 - val_accuracy: 0.9946\n",
      "Epoch 74/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0317 - accuracy: 0.9952 - val_loss: 0.0233 - val_accuracy: 0.9954\n",
      "Epoch 75/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0317 - accuracy: 0.9954 - val_loss: 0.0231 - val_accuracy: 0.9962\n",
      "Epoch 76/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0314 - accuracy: 0.9950 - val_loss: 0.0233 - val_accuracy: 0.9954\n",
      "Epoch 77/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0313 - accuracy: 0.9954 - val_loss: 0.0231 - val_accuracy: 0.9954\n",
      "Epoch 78/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0314 - accuracy: 0.9946 - val_loss: 0.0230 - val_accuracy: 0.9954\n",
      "Epoch 79/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0309 - accuracy: 0.9950 - val_loss: 0.0232 - val_accuracy: 0.9954\n",
      "Epoch 80/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0312 - accuracy: 0.9950 - val_loss: 0.0230 - val_accuracy: 0.9954\n",
      "Epoch 81/300\n",
      "5197/5197 [==============================] - 0s 38us/sample - loss: 0.0309 - accuracy: 0.9950 - val_loss: 0.0226 - val_accuracy: 0.9954\n",
      "Epoch 82/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0310 - accuracy: 0.9952 - val_loss: 0.0224 - val_accuracy: 0.9954\n",
      "Epoch 83/300\n",
      "5197/5197 [==============================] - 0s 37us/sample - loss: 0.0306 - accuracy: 0.9954 - val_loss: 0.0222 - val_accuracy: 0.9954\n",
      "Epoch 84/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0304 - accuracy: 0.9952 - val_loss: 0.0225 - val_accuracy: 0.9954\n",
      "Epoch 85/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0306 - accuracy: 0.9952 - val_loss: 0.0224 - val_accuracy: 0.9946\n",
      "Epoch 86/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0303 - accuracy: 0.9950 - val_loss: 0.0221 - val_accuracy: 0.9954\n",
      "Epoch 87/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0301 - accuracy: 0.9956 - val_loss: 0.0234 - val_accuracy: 0.9954\n",
      "Epoch 88/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0300 - accuracy: 0.9956 - val_loss: 0.0223 - val_accuracy: 0.9954\n",
      "Epoch 89/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0300 - accuracy: 0.9946 - val_loss: 0.0221 - val_accuracy: 0.9954\n",
      "Epoch 90/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0297 - accuracy: 0.9954 - val_loss: 0.0226 - val_accuracy: 0.9954\n",
      "Epoch 91/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0303 - accuracy: 0.9952 - val_loss: 0.0214 - val_accuracy: 0.9946\n",
      "Epoch 92/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0298 - accuracy: 0.9954 - val_loss: 0.0218 - val_accuracy: 0.9954\n",
      "Epoch 93/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0293 - accuracy: 0.9958 - val_loss: 0.0213 - val_accuracy: 0.9954\n",
      "Epoch 94/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0294 - accuracy: 0.9950 - val_loss: 0.0214 - val_accuracy: 0.9954\n",
      "Epoch 95/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0291 - accuracy: 0.9960 - val_loss: 0.0211 - val_accuracy: 0.9946\n",
      "Epoch 96/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0292 - accuracy: 0.9956 - val_loss: 0.0210 - val_accuracy: 0.9962\n",
      "Epoch 97/300\n",
      "5197/5197 [==============================] - 0s 37us/sample - loss: 0.0294 - accuracy: 0.9952 - val_loss: 0.0209 - val_accuracy: 0.9962\n",
      "Epoch 98/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0287 - accuracy: 0.9956 - val_loss: 0.0220 - val_accuracy: 0.9954\n",
      "Epoch 99/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0290 - accuracy: 0.9954 - val_loss: 0.0207 - val_accuracy: 0.9954\n",
      "Epoch 100/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0293 - accuracy: 0.9956 - val_loss: 0.0205 - val_accuracy: 0.9962\n",
      "Epoch 101/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0289 - accuracy: 0.9958 - val_loss: 0.0208 - val_accuracy: 0.9954\n",
      "Epoch 102/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0286 - accuracy: 0.9956 - val_loss: 0.0206 - val_accuracy: 0.9954\n",
      "Epoch 103/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0287 - accuracy: 0.9956 - val_loss: 0.0207 - val_accuracy: 0.9954\n",
      "Epoch 104/300\n",
      "5197/5197 [==============================] - 0s 37us/sample - loss: 0.0284 - accuracy: 0.9958 - val_loss: 0.0209 - val_accuracy: 0.9954\n",
      "Epoch 105/300\n",
      "5197/5197 [==============================] - 0s 33us/sample - loss: 0.0285 - accuracy: 0.9954 - val_loss: 0.0201 - val_accuracy: 0.9954\n",
      "Epoch 106/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0287 - accuracy: 0.9958 - val_loss: 0.0202 - val_accuracy: 0.9962\n",
      "Epoch 107/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0282 - accuracy: 0.9958 - val_loss: 0.0199 - val_accuracy: 0.9962\n",
      "Epoch 108/300\n",
      "5197/5197 [==============================] - 0s 33us/sample - loss: 0.0281 - accuracy: 0.9958 - val_loss: 0.0204 - val_accuracy: 0.9954\n",
      "Epoch 109/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0283 - accuracy: 0.9956 - val_loss: 0.0197 - val_accuracy: 0.9962\n",
      "Epoch 110/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0282 - accuracy: 0.9956 - val_loss: 0.0197 - val_accuracy: 0.9962\n",
      "Epoch 111/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0278 - accuracy: 0.9962 - val_loss: 0.0209 - val_accuracy: 0.9946\n",
      "Epoch 112/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0278 - accuracy: 0.9956 - val_loss: 0.0200 - val_accuracy: 0.9954\n",
      "Epoch 113/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0278 - accuracy: 0.9958 - val_loss: 0.0195 - val_accuracy: 0.9962\n",
      "Epoch 114/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0279 - accuracy: 0.9954 - val_loss: 0.0194 - val_accuracy: 0.9962\n",
      "Epoch 115/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0277 - accuracy: 0.9958 - val_loss: 0.0195 - val_accuracy: 0.9954\n",
      "Epoch 116/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0278 - accuracy: 0.9960 - val_loss: 0.0202 - val_accuracy: 0.9954\n",
      "Epoch 117/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0275 - accuracy: 0.9960 - val_loss: 0.0202 - val_accuracy: 0.9954\n",
      "Epoch 118/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0273 - accuracy: 0.9963 - val_loss: 0.0193 - val_accuracy: 0.9954\n",
      "Epoch 119/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0275 - accuracy: 0.9958 - val_loss: 0.0192 - val_accuracy: 0.9954\n",
      "Epoch 120/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0272 - accuracy: 0.9958 - val_loss: 0.0189 - val_accuracy: 0.9962\n",
      "Epoch 121/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0270 - accuracy: 0.9963 - val_loss: 0.0188 - val_accuracy: 0.9962\n",
      "Epoch 122/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0270 - accuracy: 0.9958 - val_loss: 0.0190 - val_accuracy: 0.9962\n",
      "Epoch 123/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0267 - accuracy: 0.9962 - val_loss: 0.0190 - val_accuracy: 0.9954\n",
      "Epoch 124/300\n",
      "5197/5197 [==============================] - 0s 33us/sample - loss: 0.0271 - accuracy: 0.9956 - val_loss: 0.0187 - val_accuracy: 0.9962\n",
      "Epoch 125/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0271 - accuracy: 0.9963 - val_loss: 0.0186 - val_accuracy: 0.9962\n",
      "Epoch 126/300\n",
      "5197/5197 [==============================] - 0s 37us/sample - loss: 0.0272 - accuracy: 0.9958 - val_loss: 0.0184 - val_accuracy: 0.9962\n",
      "Epoch 127/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0269 - accuracy: 0.9956 - val_loss: 0.0184 - val_accuracy: 0.9962\n",
      "Epoch 128/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0268 - accuracy: 0.9960 - val_loss: 0.0183 - val_accuracy: 0.9962\n",
      "Epoch 129/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0268 - accuracy: 0.9963 - val_loss: 0.0203 - val_accuracy: 0.9962\n",
      "Epoch 130/300\n",
      "5197/5197 [==============================] - 0s 37us/sample - loss: 0.0267 - accuracy: 0.9963 - val_loss: 0.0182 - val_accuracy: 0.9962\n",
      "Epoch 131/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0268 - accuracy: 0.9965 - val_loss: 0.0182 - val_accuracy: 0.9962\n",
      "Epoch 132/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0263 - accuracy: 0.9962 - val_loss: 0.0182 - val_accuracy: 0.9962\n",
      "Epoch 133/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0265 - accuracy: 0.9962 - val_loss: 0.0181 - val_accuracy: 0.9962\n",
      "Epoch 134/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0264 - accuracy: 0.9962 - val_loss: 0.0179 - val_accuracy: 0.9962\n",
      "Epoch 135/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0263 - accuracy: 0.9962 - val_loss: 0.0178 - val_accuracy: 0.9962\n",
      "Epoch 136/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0261 - accuracy: 0.9962 - val_loss: 0.0179 - val_accuracy: 0.9962\n",
      "Epoch 137/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0260 - accuracy: 0.9963 - val_loss: 0.0178 - val_accuracy: 0.9962\n",
      "Epoch 138/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0260 - accuracy: 0.9960 - val_loss: 0.0181 - val_accuracy: 0.9969\n",
      "Epoch 139/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0260 - accuracy: 0.9963 - val_loss: 0.0177 - val_accuracy: 0.9962\n",
      "Epoch 140/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0258 - accuracy: 0.9965 - val_loss: 0.0176 - val_accuracy: 0.9962\n",
      "Epoch 141/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0260 - accuracy: 0.9963 - val_loss: 0.0176 - val_accuracy: 0.9962\n",
      "Epoch 142/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0260 - accuracy: 0.9960 - val_loss: 0.0178 - val_accuracy: 0.9954\n",
      "Epoch 143/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0259 - accuracy: 0.9960 - val_loss: 0.0177 - val_accuracy: 0.9962\n",
      "Epoch 144/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0258 - accuracy: 0.9956 - val_loss: 0.0180 - val_accuracy: 0.9969\n",
      "Epoch 145/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0259 - accuracy: 0.9963 - val_loss: 0.0174 - val_accuracy: 0.9962\n",
      "Epoch 146/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0256 - accuracy: 0.9960 - val_loss: 0.0178 - val_accuracy: 0.9969\n",
      "Epoch 147/300\n",
      "5197/5197 [==============================] - 0s 33us/sample - loss: 0.0259 - accuracy: 0.9958 - val_loss: 0.0175 - val_accuracy: 0.9962\n",
      "Epoch 148/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0256 - accuracy: 0.9963 - val_loss: 0.0176 - val_accuracy: 0.9954\n",
      "Epoch 149/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0257 - accuracy: 0.9962 - val_loss: 0.0173 - val_accuracy: 0.9962\n",
      "Epoch 150/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0261 - accuracy: 0.9960 - val_loss: 0.0174 - val_accuracy: 0.9962\n",
      "Epoch 151/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0255 - accuracy: 0.9960 - val_loss: 0.0171 - val_accuracy: 0.9962\n",
      "Epoch 152/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0253 - accuracy: 0.9969 - val_loss: 0.0171 - val_accuracy: 0.9962\n",
      "Epoch 153/300\n",
      "5197/5197 [==============================] - 0s 38us/sample - loss: 0.0256 - accuracy: 0.9963 - val_loss: 0.0170 - val_accuracy: 0.9962\n",
      "Epoch 154/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0256 - accuracy: 0.9962 - val_loss: 0.0172 - val_accuracy: 0.9969\n",
      "Epoch 155/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0251 - accuracy: 0.9965 - val_loss: 0.0178 - val_accuracy: 0.9969\n",
      "Epoch 156/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0254 - accuracy: 0.9962 - val_loss: 0.0176 - val_accuracy: 0.9954\n",
      "Epoch 157/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0250 - accuracy: 0.9962 - val_loss: 0.0174 - val_accuracy: 0.9969\n",
      "Epoch 158/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0249 - accuracy: 0.9963 - val_loss: 0.0168 - val_accuracy: 0.9962\n",
      "Epoch 159/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0254 - accuracy: 0.9965 - val_loss: 0.0173 - val_accuracy: 0.9969\n",
      "Epoch 160/300\n",
      "5197/5197 [==============================] - 0s 37us/sample - loss: 0.0252 - accuracy: 0.9969 - val_loss: 0.0167 - val_accuracy: 0.9962\n",
      "Epoch 161/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0250 - accuracy: 0.9962 - val_loss: 0.0167 - val_accuracy: 0.9962\n",
      "Epoch 162/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0250 - accuracy: 0.9962 - val_loss: 0.0170 - val_accuracy: 0.9962\n",
      "Epoch 163/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0248 - accuracy: 0.9963 - val_loss: 0.0172 - val_accuracy: 0.9969\n",
      "Epoch 164/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0245 - accuracy: 0.9965 - val_loss: 0.0167 - val_accuracy: 0.9977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0248 - accuracy: 0.9973 - val_loss: 0.0165 - val_accuracy: 0.9969\n",
      "Epoch 166/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0250 - accuracy: 0.9960 - val_loss: 0.0167 - val_accuracy: 0.9977\n",
      "Epoch 167/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0246 - accuracy: 0.9967 - val_loss: 0.0166 - val_accuracy: 0.9977\n",
      "Epoch 168/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0242 - accuracy: 0.9967 - val_loss: 0.0163 - val_accuracy: 0.9962\n",
      "Epoch 169/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0246 - accuracy: 0.9960 - val_loss: 0.0161 - val_accuracy: 0.9969\n",
      "Epoch 170/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0243 - accuracy: 0.9965 - val_loss: 0.0172 - val_accuracy: 0.9962\n",
      "Epoch 171/300\n",
      "5197/5197 [==============================] - 0s 37us/sample - loss: 0.0244 - accuracy: 0.9967 - val_loss: 0.0160 - val_accuracy: 0.9969\n",
      "Epoch 172/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0241 - accuracy: 0.9969 - val_loss: 0.0166 - val_accuracy: 0.9977\n",
      "Epoch 173/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0244 - accuracy: 0.9962 - val_loss: 0.0161 - val_accuracy: 0.9977\n",
      "Epoch 174/300\n",
      "5197/5197 [==============================] - 0s 37us/sample - loss: 0.0242 - accuracy: 0.9962 - val_loss: 0.0174 - val_accuracy: 0.9969\n",
      "Epoch 175/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0240 - accuracy: 0.9967 - val_loss: 0.0165 - val_accuracy: 0.9977\n",
      "Epoch 176/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0238 - accuracy: 0.9965 - val_loss: 0.0169 - val_accuracy: 0.9969\n",
      "Epoch 177/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0240 - accuracy: 0.9967 - val_loss: 0.0156 - val_accuracy: 0.9969\n",
      "Epoch 178/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0240 - accuracy: 0.9965 - val_loss: 0.0157 - val_accuracy: 0.9962\n",
      "Epoch 179/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0237 - accuracy: 0.9967 - val_loss: 0.0156 - val_accuracy: 0.9962\n",
      "Epoch 180/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0240 - accuracy: 0.9958 - val_loss: 0.0156 - val_accuracy: 0.9962\n",
      "Epoch 181/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0236 - accuracy: 0.9965 - val_loss: 0.0156 - val_accuracy: 0.9977\n",
      "Epoch 182/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0233 - accuracy: 0.9969 - val_loss: 0.0153 - val_accuracy: 0.9969\n",
      "Epoch 183/300\n",
      "5197/5197 [==============================] - 0s 37us/sample - loss: 0.0237 - accuracy: 0.9963 - val_loss: 0.0153 - val_accuracy: 0.9977\n",
      "Epoch 184/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0233 - accuracy: 0.9967 - val_loss: 0.0157 - val_accuracy: 0.9977\n",
      "Epoch 185/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0232 - accuracy: 0.9967 - val_loss: 0.0153 - val_accuracy: 0.9969\n",
      "Epoch 186/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0232 - accuracy: 0.9963 - val_loss: 0.0159 - val_accuracy: 0.9977\n",
      "Epoch 187/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0234 - accuracy: 0.9962 - val_loss: 0.0155 - val_accuracy: 0.9977\n",
      "Epoch 188/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0232 - accuracy: 0.9963 - val_loss: 0.0151 - val_accuracy: 0.9969\n",
      "Epoch 189/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0233 - accuracy: 0.9963 - val_loss: 0.0152 - val_accuracy: 0.9977\n",
      "Epoch 190/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0231 - accuracy: 0.9965 - val_loss: 0.0152 - val_accuracy: 0.9977\n",
      "Epoch 191/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0229 - accuracy: 0.9967 - val_loss: 0.0152 - val_accuracy: 0.9977\n",
      "Epoch 192/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0230 - accuracy: 0.9967 - val_loss: 0.0149 - val_accuracy: 0.9977\n",
      "Epoch 193/300\n",
      "5197/5197 [==============================] - 0s 33us/sample - loss: 0.0231 - accuracy: 0.9969 - val_loss: 0.0155 - val_accuracy: 0.9962\n",
      "Epoch 194/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0228 - accuracy: 0.9963 - val_loss: 0.0150 - val_accuracy: 0.9977\n",
      "Epoch 195/300\n",
      "5197/5197 [==============================] - 0s 33us/sample - loss: 0.0226 - accuracy: 0.9967 - val_loss: 0.0151 - val_accuracy: 0.9977\n",
      "Epoch 196/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0226 - accuracy: 0.9965 - val_loss: 0.0153 - val_accuracy: 0.9977\n",
      "Epoch 197/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0224 - accuracy: 0.9967 - val_loss: 0.0149 - val_accuracy: 0.9977\n",
      "Epoch 198/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0225 - accuracy: 0.9965 - val_loss: 0.0148 - val_accuracy: 0.9977\n",
      "Epoch 199/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0225 - accuracy: 0.9971 - val_loss: 0.0153 - val_accuracy: 0.9954\n",
      "Epoch 200/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0223 - accuracy: 0.9969 - val_loss: 0.0149 - val_accuracy: 0.9977\n",
      "Epoch 201/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0223 - accuracy: 0.9963 - val_loss: 0.0159 - val_accuracy: 0.9969\n",
      "Epoch 202/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0222 - accuracy: 0.9965 - val_loss: 0.0153 - val_accuracy: 0.9954\n",
      "Epoch 203/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0222 - accuracy: 0.9969 - val_loss: 0.0149 - val_accuracy: 0.9977\n",
      "Epoch 204/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0222 - accuracy: 0.9963 - val_loss: 0.0148 - val_accuracy: 0.9977\n",
      "Epoch 205/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0222 - accuracy: 0.9971 - val_loss: 0.0155 - val_accuracy: 0.9977\n",
      "Epoch 206/300\n",
      "5197/5197 [==============================] - 0s 37us/sample - loss: 0.0221 - accuracy: 0.9963 - val_loss: 0.0152 - val_accuracy: 0.9954\n",
      "Epoch 207/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0216 - accuracy: 0.9967 - val_loss: 0.0150 - val_accuracy: 0.9977\n",
      "Epoch 208/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0222 - accuracy: 0.9967 - val_loss: 0.0153 - val_accuracy: 0.9969\n",
      "Epoch 209/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0218 - accuracy: 0.9967 - val_loss: 0.0144 - val_accuracy: 0.9977\n",
      "Epoch 210/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0218 - accuracy: 0.9965 - val_loss: 0.0146 - val_accuracy: 0.9977\n",
      "Epoch 211/300\n",
      "5197/5197 [==============================] - 0s 33us/sample - loss: 0.0216 - accuracy: 0.9965 - val_loss: 0.0147 - val_accuracy: 0.9977\n",
      "Epoch 212/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0220 - accuracy: 0.9965 - val_loss: 0.0142 - val_accuracy: 0.9977\n",
      "Epoch 213/300\n",
      "5197/5197 [==============================] - 0s 39us/sample - loss: 0.0214 - accuracy: 0.9973 - val_loss: 0.0145 - val_accuracy: 0.9977\n",
      "Epoch 214/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0214 - accuracy: 0.9967 - val_loss: 0.0151 - val_accuracy: 0.9977\n",
      "Epoch 215/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0213 - accuracy: 0.9967 - val_loss: 0.0142 - val_accuracy: 0.9977\n",
      "Epoch 216/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0214 - accuracy: 0.9965 - val_loss: 0.0142 - val_accuracy: 0.9977\n",
      "Epoch 217/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0213 - accuracy: 0.9969 - val_loss: 0.0144 - val_accuracy: 0.9977\n",
      "Epoch 218/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0215 - accuracy: 0.9965 - val_loss: 0.0142 - val_accuracy: 0.9977\n",
      "Epoch 219/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0211 - accuracy: 0.9969 - val_loss: 0.0141 - val_accuracy: 0.9977\n",
      "Epoch 220/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0213 - accuracy: 0.9969 - val_loss: 0.0141 - val_accuracy: 0.9977\n",
      "Epoch 221/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0210 - accuracy: 0.9971 - val_loss: 0.0140 - val_accuracy: 0.9977\n",
      "Epoch 222/300\n",
      "5197/5197 [==============================] - 0s 37us/sample - loss: 0.0209 - accuracy: 0.9967 - val_loss: 0.0140 - val_accuracy: 0.9977\n",
      "Epoch 223/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0208 - accuracy: 0.9971 - val_loss: 0.0142 - val_accuracy: 0.9962\n",
      "Epoch 224/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0207 - accuracy: 0.9973 - val_loss: 0.0138 - val_accuracy: 0.9977\n",
      "Epoch 225/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0210 - accuracy: 0.9963 - val_loss: 0.0139 - val_accuracy: 0.9977\n",
      "Epoch 226/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0207 - accuracy: 0.9969 - val_loss: 0.0139 - val_accuracy: 0.9977\n",
      "Epoch 227/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0206 - accuracy: 0.9969 - val_loss: 0.0138 - val_accuracy: 0.9977\n",
      "Epoch 228/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0207 - accuracy: 0.9965 - val_loss: 0.0142 - val_accuracy: 0.9962\n",
      "Epoch 229/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0204 - accuracy: 0.9967 - val_loss: 0.0153 - val_accuracy: 0.9969\n",
      "Epoch 230/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0207 - accuracy: 0.9967 - val_loss: 0.0138 - val_accuracy: 0.9977\n",
      "Epoch 231/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0207 - accuracy: 0.9963 - val_loss: 0.0139 - val_accuracy: 0.9977\n",
      "Epoch 232/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0205 - accuracy: 0.9969 - val_loss: 0.0138 - val_accuracy: 0.9977\n",
      "Epoch 233/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0203 - accuracy: 0.9967 - val_loss: 0.0137 - val_accuracy: 0.9977\n",
      "Epoch 234/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0202 - accuracy: 0.9967 - val_loss: 0.0135 - val_accuracy: 0.9977\n",
      "Epoch 235/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0205 - accuracy: 0.9967 - val_loss: 0.0137 - val_accuracy: 0.9969\n",
      "Epoch 236/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0201 - accuracy: 0.9969 - val_loss: 0.0137 - val_accuracy: 0.9977\n",
      "Epoch 237/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0203 - accuracy: 0.9967 - val_loss: 0.0149 - val_accuracy: 0.9969\n",
      "Epoch 238/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0204 - accuracy: 0.9967 - val_loss: 0.0133 - val_accuracy: 0.9977\n",
      "Epoch 239/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0201 - accuracy: 0.9965 - val_loss: 0.0132 - val_accuracy: 0.9977\n",
      "Epoch 240/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0201 - accuracy: 0.9967 - val_loss: 0.0141 - val_accuracy: 0.9962\n",
      "Epoch 241/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0202 - accuracy: 0.9969 - val_loss: 0.0139 - val_accuracy: 0.9977\n",
      "Epoch 242/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0200 - accuracy: 0.9969 - val_loss: 0.0134 - val_accuracy: 0.9977\n",
      "Epoch 243/300\n",
      "5197/5197 [==============================] - 0s 37us/sample - loss: 0.0201 - accuracy: 0.9969 - val_loss: 0.0134 - val_accuracy: 0.9977\n",
      "Epoch 244/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0199 - accuracy: 0.9969 - val_loss: 0.0132 - val_accuracy: 0.9977\n",
      "Epoch 245/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0198 - accuracy: 0.9969 - val_loss: 0.0137 - val_accuracy: 0.9969\n",
      "Epoch 246/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0198 - accuracy: 0.9967 - val_loss: 0.0133 - val_accuracy: 0.9977\n",
      "Epoch 247/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0197 - accuracy: 0.9969 - val_loss: 0.0139 - val_accuracy: 0.9962\n",
      "Epoch 248/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0197 - accuracy: 0.9971 - val_loss: 0.0132 - val_accuracy: 0.9977\n",
      "Epoch 249/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0196 - accuracy: 0.9969 - val_loss: 0.0130 - val_accuracy: 0.9977\n",
      "Epoch 250/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0196 - accuracy: 0.9969 - val_loss: 0.0135 - val_accuracy: 0.9977\n",
      "Epoch 251/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0196 - accuracy: 0.9967 - val_loss: 0.0130 - val_accuracy: 0.9977\n",
      "Epoch 252/300\n",
      "5197/5197 [==============================] - 0s 38us/sample - loss: 0.0194 - accuracy: 0.9971 - val_loss: 0.0130 - val_accuracy: 0.9969\n",
      "Epoch 253/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0195 - accuracy: 0.9969 - val_loss: 0.0130 - val_accuracy: 0.9977\n",
      "Epoch 254/300\n",
      "5197/5197 [==============================] - 0s 37us/sample - loss: 0.0195 - accuracy: 0.9969 - val_loss: 0.0132 - val_accuracy: 0.9977\n",
      "Epoch 255/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0193 - accuracy: 0.9971 - val_loss: 0.0137 - val_accuracy: 0.9962\n",
      "Epoch 256/300\n",
      "5197/5197 [==============================] - 0s 33us/sample - loss: 0.0194 - accuracy: 0.9963 - val_loss: 0.0128 - val_accuracy: 0.9977\n",
      "Epoch 257/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0197 - accuracy: 0.9965 - val_loss: 0.0129 - val_accuracy: 0.9977\n",
      "Epoch 258/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0191 - accuracy: 0.9967 - val_loss: 0.0128 - val_accuracy: 0.9977\n",
      "Epoch 259/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0192 - accuracy: 0.9969 - val_loss: 0.0130 - val_accuracy: 0.9969\n",
      "Epoch 260/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0193 - accuracy: 0.9969 - val_loss: 0.0127 - val_accuracy: 0.9977\n",
      "Epoch 261/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0191 - accuracy: 0.9971 - val_loss: 0.0127 - val_accuracy: 0.9977\n",
      "Epoch 262/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0189 - accuracy: 0.9969 - val_loss: 0.0128 - val_accuracy: 0.9977\n",
      "Epoch 263/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0190 - accuracy: 0.9971 - val_loss: 0.0128 - val_accuracy: 0.9977\n",
      "Epoch 264/300\n",
      "5197/5197 [==============================] - ETA: 0s - loss: 0.0190 - accuracy: 0.99 - 0s 38us/sample - loss: 0.0189 - accuracy: 0.9963 - val_loss: 0.0128 - val_accuracy: 0.9977\n",
      "Epoch 265/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0189 - accuracy: 0.9969 - val_loss: 0.0128 - val_accuracy: 0.9977\n",
      "Epoch 266/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0187 - accuracy: 0.9965 - val_loss: 0.0140 - val_accuracy: 0.9962\n",
      "Epoch 267/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0188 - accuracy: 0.9973 - val_loss: 0.0131 - val_accuracy: 0.9969\n",
      "Epoch 268/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0185 - accuracy: 0.9971 - val_loss: 0.0145 - val_accuracy: 0.9962\n",
      "Epoch 269/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0194 - accuracy: 0.9965 - val_loss: 0.0129 - val_accuracy: 0.9969\n",
      "Epoch 270/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0185 - accuracy: 0.9969 - val_loss: 0.0127 - val_accuracy: 0.9969\n",
      "Epoch 271/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0187 - accuracy: 0.9967 - val_loss: 0.0127 - val_accuracy: 0.9977\n",
      "Epoch 272/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0186 - accuracy: 0.9965 - val_loss: 0.0126 - val_accuracy: 0.9977\n",
      "Epoch 273/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0184 - accuracy: 0.9965 - val_loss: 0.0126 - val_accuracy: 0.9977\n",
      "Epoch 274/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0185 - accuracy: 0.9967 - val_loss: 0.0125 - val_accuracy: 0.9977\n",
      "Epoch 275/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0187 - accuracy: 0.9971 - val_loss: 0.0130 - val_accuracy: 0.9969\n",
      "Epoch 276/300\n",
      "5197/5197 [==============================] - 0s 33us/sample - loss: 0.0186 - accuracy: 0.9967 - val_loss: 0.0124 - val_accuracy: 0.9977\n",
      "Epoch 277/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0185 - accuracy: 0.9967 - val_loss: 0.0131 - val_accuracy: 0.9977\n",
      "Epoch 278/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0184 - accuracy: 0.9971 - val_loss: 0.0124 - val_accuracy: 0.9969\n",
      "Epoch 279/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0184 - accuracy: 0.9967 - val_loss: 0.0126 - val_accuracy: 0.9977\n",
      "Epoch 280/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0184 - accuracy: 0.9969 - val_loss: 0.0125 - val_accuracy: 0.9977\n",
      "Epoch 281/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0187 - accuracy: 0.9965 - val_loss: 0.0126 - val_accuracy: 0.9977\n",
      "Epoch 282/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0183 - accuracy: 0.9965 - val_loss: 0.0123 - val_accuracy: 0.9977\n",
      "Epoch 283/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0181 - accuracy: 0.9967 - val_loss: 0.0127 - val_accuracy: 0.9977\n",
      "Epoch 284/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0187 - accuracy: 0.9971 - val_loss: 0.0132 - val_accuracy: 0.9977\n",
      "Epoch 285/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0182 - accuracy: 0.9967 - val_loss: 0.0127 - val_accuracy: 0.9977\n",
      "Epoch 286/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0179 - accuracy: 0.9965 - val_loss: 0.0135 - val_accuracy: 0.9977\n",
      "Epoch 287/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0183 - accuracy: 0.9969 - val_loss: 0.0123 - val_accuracy: 0.9977\n",
      "Epoch 288/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0180 - accuracy: 0.9971 - val_loss: 0.0123 - val_accuracy: 0.9977\n",
      "Epoch 289/300\n",
      "5197/5197 [==============================] - 0s 35us/sample - loss: 0.0179 - accuracy: 0.9967 - val_loss: 0.0122 - val_accuracy: 0.9977\n",
      "Epoch 290/300\n",
      "5197/5197 [==============================] - 0s 33us/sample - loss: 0.0180 - accuracy: 0.9965 - val_loss: 0.0126 - val_accuracy: 0.9977\n",
      "Epoch 291/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0181 - accuracy: 0.9969 - val_loss: 0.0135 - val_accuracy: 0.9977\n",
      "Epoch 292/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0177 - accuracy: 0.9971 - val_loss: 0.0121 - val_accuracy: 0.9977\n",
      "Epoch 293/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0179 - accuracy: 0.9967 - val_loss: 0.0122 - val_accuracy: 0.9977\n",
      "Epoch 294/300\n",
      "5197/5197 [==============================] - 0s 39us/sample - loss: 0.0178 - accuracy: 0.9971 - val_loss: 0.0125 - val_accuracy: 0.9977\n",
      "Epoch 295/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0175 - accuracy: 0.9971 - val_loss: 0.0129 - val_accuracy: 0.9969\n",
      "Epoch 296/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0180 - accuracy: 0.9967 - val_loss: 0.0119 - val_accuracy: 0.9977\n",
      "Epoch 297/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0177 - accuracy: 0.9969 - val_loss: 0.0120 - val_accuracy: 0.9977\n",
      "Epoch 298/300\n",
      "5197/5197 [==============================] - 0s 34us/sample - loss: 0.0175 - accuracy: 0.9969 - val_loss: 0.0121 - val_accuracy: 0.9977\n",
      "Epoch 299/300\n",
      "5197/5197 [==============================] - 0s 36us/sample - loss: 0.0178 - accuracy: 0.9967 - val_loss: 0.0120 - val_accuracy: 0.9977\n",
      "Epoch 300/300\n",
      "5197/5197 [==============================] - 0s 37us/sample - loss: 0.0178 - accuracy: 0.9967 - val_loss: 0.0125 - val_accuracy: 0.9977\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26b275440b8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=scaled_X_train, \n",
    "          y=y_train, \n",
    "          epochs=300,\n",
    "          validation_data=(scaled_X_test, y_test), verbose=1 ,callbacks=[early_stop]         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.567689</td>\n",
       "      <td>0.751395</td>\n",
       "      <td>0.494311</td>\n",
       "      <td>0.763846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.448160</td>\n",
       "      <td>0.751395</td>\n",
       "      <td>0.363825</td>\n",
       "      <td>0.763846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.274158</td>\n",
       "      <td>0.894747</td>\n",
       "      <td>0.207222</td>\n",
       "      <td>0.950769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.167220</td>\n",
       "      <td>0.967866</td>\n",
       "      <td>0.138907</td>\n",
       "      <td>0.974615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.120307</td>\n",
       "      <td>0.976140</td>\n",
       "      <td>0.106437</td>\n",
       "      <td>0.979231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0.018033</td>\n",
       "      <td>0.996729</td>\n",
       "      <td>0.011947</td>\n",
       "      <td>0.997692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0.017681</td>\n",
       "      <td>0.996921</td>\n",
       "      <td>0.011956</td>\n",
       "      <td>0.997692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0.017481</td>\n",
       "      <td>0.996921</td>\n",
       "      <td>0.012072</td>\n",
       "      <td>0.997692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.017814</td>\n",
       "      <td>0.996729</td>\n",
       "      <td>0.011998</td>\n",
       "      <td>0.997692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.017819</td>\n",
       "      <td>0.996729</td>\n",
       "      <td>0.012471</td>\n",
       "      <td>0.997692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  accuracy  val_loss  val_accuracy\n",
       "0    0.567689  0.751395  0.494311      0.763846\n",
       "1    0.448160  0.751395  0.363825      0.763846\n",
       "2    0.274158  0.894747  0.207222      0.950769\n",
       "3    0.167220  0.967866  0.138907      0.974615\n",
       "4    0.120307  0.976140  0.106437      0.979231\n",
       "..        ...       ...       ...           ...\n",
       "295  0.018033  0.996729  0.011947      0.997692\n",
       "296  0.017681  0.996921  0.011956      0.997692\n",
       "297  0.017481  0.996921  0.012072      0.997692\n",
       "298  0.017814  0.996729  0.011998      0.997692\n",
       "299  0.017819  0.996729  0.012471      0.997692\n",
       "\n",
       "[300 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['loss','val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAn/UlEQVR4nO3deXyU5b338c9vJhtZgATCjgKKsocloh5bN1zQaq0rWp/W8mg99qh1eU7V0lrpy56entP69Gi1UmzVeqrVU5dT9fG4oCi2WBVkB1FWCUESEiAJZJ35PX/MJExCQgYMTXLzfb9eeSVzb3Ndc8M3V35zz3WbuyMiIsEV6uwGiIjI4aWgFxEJOAW9iEjAKehFRAJOQS8iEnApnd2A1vTt29eHDRvW2c0QEek2Fi9evMPd81tb1yWDftiwYSxatKizmyEi0m2Y2ea21ql0IyIScAp6EZGAU9CLiARcu0FvZo+aWYmZrWxjvZnZA2a2zsyWm9nkhHXTzWxtfN1dHdlwERFJTjIj+seB6QdYfx4wMv51PfAwgJmFgYfi68cAV5nZmC/SWBEROXjtBr27LwDKD7DJRcATHvM3oLeZDQSmAuvcfYO71wFPx7cVEZG/o46o0Q8GtiQ8Loova2t5q8zsejNbZGaLSktLO6BZIiICHXMdvbWyzA+wvFXuPheYC1BYWKi5kyUY6qth6ZOU9RpH7q6VhPbugAlXQN6I2PpoBJY/A+UbYfiXoaoEMvvAMWc0P87mhbC3HFIyYMv7kH88ZOXDpr/EjpV7NKyfv2/7vsfB0Kmw7I+x52iUO4zIyHMJr/lvmDAjtmzRo1BbRTSzL6GJV8KKP8FR/wCfvBprf9yeugZ6pIYJWWv/tSHqTiicQt3YGez+dCF5ezcSDhmYwdiLoe/xsPI52PFJ8x0HTwGPxr5S0mHLB3D0ybHXYc3LzdpOn2OhYis+sABf9gyhxkjJ7kdkcCHhT1+D7H5Ej/sKoaX/CQ21kJ4Dx06Dta8Qqa8lbIa7Y2aQng1TZrJlbwo9M1LplZkKNRWw5D+helfs2KEwfty5WNEi2LMDH3k2fL4Cqyhu1g2Pt8Xi0Rd1x2zf46Yp4Q3q+owmJTOX8Jb3mr8WaVnwpVtbfX2/CEtmPnozGwa87O7jWln3G+Btd/9j/PFa4HRgGDDb3c+NL/8+gLv/a3vPV1hY6Ef0B6Z2fQY9B0MoDOUboOcQSEnbt37nZujRGzJ6tb5/RXEsEDLz4o+3Qclq6DsSeh8VW7anDGp2QZ9jOqzZNXUNZGxfApE6OOoksBBsWwr9x0E4tfnGxUugZjcMmQrl62FvGet6jCe/d096Va6HymIYNIldnkVlTQOrinfTv2cGBVm7WL1qKalhI2PweDJSoGrLKmoaIowZ2JP6SJQ12yrYXlFDVW2EkBnD+2YSCllCOyPkFb9D/4rlLMyfQVk0iz75gxg5djIDVswh5dP/4bOcSQyt+Ii9J9zEG3Yyx9Wuon+WsXHHXl5b9Tlfyt3FSTuepa4hymejr2PE5j9RlF1A75L3eYsT6DHiZMb0rGXIsl+SU721WddLw/2JZg9gR8Ywsneu5ui6T/d7LXeF+7ChxzgW9pzOsTkRzvr0XlKite2egyjWFH6Vlk2OVxGNB03j8vXRgRwT2kZlWj4b0kZRUPVu034laUfRr+6zZsdr0tbwLWF9yJxdnkVv29OsPRWhXuxIHcSI2jXNjhtqY+wXIUQt6WRS3axPjXZ7Fr1sT5vHSVyfuC7qFutDvC8hnE9SjydSW83C6FjOzVhFbkMpWfHnPVAboy1fjJavTxuPWx4v8TiV4Vx63b2x1edrj5ktdvfCVtd1QNB/BbgJOB84EXjA3aeaWQrwCTAN2Ap8CHzd3Ve193yBDPrKz+Evv4SCqyCUAu/PiS0/7Y594QuwcxP8qhBGXxDb9o9XwjHT4OvPAAZ7SuCByZCaAcNPi42WhsVHgv3HQPkG/M17YfBkaqb8I6kf/zf26euEIzV4KJWqKd9hY20Ox626n7TIXjbmfYn6UAYDemZQVdcAQEPE2VPbQF1DFM/qy47ciQwpeYcdFXtJDYcYkteD4uo0tuSeyIDP51NdXU2PrGzW74xwTcobAGxMGYGH0hhR9zHrGMJnKcMJmVFdH2FIaiXj65cDsMuz6W1VALwbGUdJKJ9LLTYy3UlP/hIZg8f/I6RTz5mhJaRabIS619MJEyXd6g/6dETdKKUX/W3Xvpfes8m1Kj73PAZYOds8j4FWTrlnkxdvY6KPoseSRyXDQtup9VTSrb5p30brooO4z/8X5+UV86fSIdSk9OQPodlUeA9yqWRXqDfP9PknHt42kq/zKhXhXAan13C8b+DLDe/Rg1i4F3lf/tzjEurqI/y+/gxm9lqCV5XwcPU0zgp9xNG2ncci55LXO5eBOSn8sPJextZ8xNfr72Znn0nsqW0gNyPEQ5XfZXj0M/6acRpjqxfR2/bwSo8LuKXiav6UfR8TaxfxYcpktqaN4I20abxf1Y9INEpqOMQFEwaxvrSK3dX1lFTUMCI/m6Kdezm6TxYDemaQl51Gw+YPuePz29meV8jlu28lOzODs/J3c+P6G6i3FH6f823m7iokLyudkf2y2VNdyznVr5CWmgpm1NXV8pKfwi/3zKKvVfCrY+ayO30AuDOu4h167dnEMXuWcFzdap4ZN5cVPpw9dRGO3r2IL6WsZl7OxZxfMpfJ5f+PG+pu5aPMUziz1zams5BF/S4hJW8YO/fUUVXbwEvLirmjz1+4vvIhKtP6kVNXwiehYyjKHM289LN4s3Io9RHn+Jxa/jH9dT7wMaxiBN+0V1jJSFZnn8in26vYubeO/Jx0Jg3NZXd1Pau3VdA3O40ThuVRtKualVt306tHKlOH5VG2p45oJMJF9g6Vu8p4Mf188nKyqaipp6yqjt6Zqfz2mhMO+t8zfMGgN7M/Ehuh9wW2A/cAqQDuPsfMDHiQ2JU5e4GZ7r4ovu/5wH8AYeBRd/+XZBrc7YO+vgZWPQ8YjP1a7Pvj58PWxfu2ScvBow1UZg6hbMbLLC+NkBIKkbnoQc747MGmzcqtN3m+i3WZExlcvwksRGpdBcvCY8mPlpLmdQxgBwANhEghymbvz9G2nXoPU2HZLIyM4anImVwafpfLwgsAWOjj2eQDOInYVbMt/xWEDEJmDPAS0q2BUu9JfUoO9RGnIeoMtHIyrZYKy6Eq1JOchnJyrJq/Zp7JK3tG8b9TXyMUjbAi5xQm1y0mtaEKB8JmVEeM5XnTqel9LCds+yMr0wvY4+lcUf4bIoR5t+8M3o2M4ZKaPzPYSgiZkRo26huirM+aSNWoy2hoaGD4xmfY02CsHXwJudk9WFW8m7SUMFOOzuXY/Cwy0sLU1EUo3l3TrG9pKSHqM/IpaujFSZnFZKYaZavegnXzWDjkOj7w0Vw6ooE1NX0YvP4Zpla+QfHIq9ni/UgNhzhxeB7VnsJnaSM5NqWU+pduY2vBLfTtP4g+Q47DyjdQVFxMZX2UXsMLGZDbk1DIeG99GcP7ZtGfMj4qhb6hKo4ePBjSs9m2u5qtO6s5tl82vTPjf71VlUD5Rt7fWEZ51jFMn3Ic7rGSQEo4RCTqfFa+l5r6CP17ZpCZFiYjNRzbN9KA7yklktWflHDCW3Gf/Q3++gB87dfUbV1G2vsPwkW/xrP6Yjs+xV//IfaVXzQffBysys9jZZdw6r4SSeV2SMuE9BwaIlHCIYstb0vdXmio2fdXaaJIfayMldO/9X2jUajcRm3WANJTwm0+RVPbyjdA72GxvyzzRsT+ku6GvvCI/u+tSwR9pB7q90JqFtRVxep8pR/H6ogA696M1U1P/qfYP+pG6T3hg7nwXiysKzOHkn78NNKWPE70qw+yeVspq7bu5KNeZ7Nl9fs8zE+ZH53ErPpr+Wnqbzk7/BGrGMGfe1xMVl0ZH/ebztQ973BFxWN8Gh3ECPuc58PnsnDYTfTskYpHnaElbxFNzeSqnXPYnZrPK8fM5qblF2M43xv4GHsyBnBF4VDWlVQxvHolx/WsZ9hJl1AbcWobImzdVc3H2yoZN7gX4ZDRIy3MwJ4ZhEKGl62nbuN7VBx7Efm9cyiprOHttaVcOCJEj01vwthLID2b8pJi8rbOh/GXxeqsh2LNy7EabL9RX/DkiRx5FPQHq6EWnvga7FgbewOpZBUMmACb3m2+XWoW1O/Zb/cIIZb0PpsnqqZyb/199LK9vB6Zwr/1/hHrS/eQmRYm6s45Ywbw3ew3OXbxvURSsgg3xI919r1wyndbtKmOPQ1GTV09uVkZhMKtXDAVaYiNRsxg8e9jdfGJX++Y10REurQDBX2XnL2y07jD/9wJHz0BDdWxIP9sIQ0pWaRsepfIl75HTf44indV88SKvSzY2ZcCVlJbV8+Q3B5s213DBD7lzNQV3F15Kb36H8WC/EEcv+IXLBt5O5tX7eXGM47h5jNH7vsT2yfCkAGE/3o/nPnD2BuvAwv2b1tKGlkpkJWRuv+6RuGE0znlmg59aUSk+9KIHiAapX53MZVvP0Dest+wJvcMtgw8l6NHjqN43XJ+vjTEKN/Em+nTqKypJxwy+uVkcPIxfYi6M6BnBgvXlzF1eB7njOnPlKNzW60/1jVESUvR9EIi0vE0oj8Ar6+m+FfnMbhiCXnAUw1n8C9l17Nnm8NHFcAwzhrdj/79z2DgxyVcPGkwpVW1/OSiceRmpbV3+GYU8iLSGY7YoK9tiPCX3/4zE7e/wGDfyUu9v0mvcWczdcKZrMzPoqSyliWf7SQ7PZVTju2DmXHndL1JKCLdzxEZ9M98sJm3336dh/c+ysepY3jvqO/ylatva/ahmv49M5g+bmAntlJEpGMccUH/xivPUvC32cwIbaEurTejbn+VUW19wlREJACOjKCv2Abzf0LNlmWcvWMFJWkDiPzDnaSNOr/taQRERAIi+EFfXwOPnktDxTaWRkexxGZw+Y3/Tji3d2e3TETk7yL4Qf/+HNi1mWvqvk902Ol8b/rx9FXIi8gRJNhB/+a9+Lv38V64kA05JzDvmkKy0oPdZRGRloJ7YXdNBf6XXzLfpnIXt/CrqyYp5EXkiBTcoN+4APMIv6k5h/u+8SUKh7UyC56IyBEguEG//i32kkHa8BM5QSEvIkewwAZ9dMM7LIyM5qSR+tCTiBzZAhv0Xvk5m3wAI/pmdXZTREQ6VTCDPholXF/FHnowIj+7s1sjItKpghn08ZuBVNGDo/tkdnJjREQ6VzCDvrYSgLTMnvtu8CEicoQKdNBn98zt5IaIiHS+gAZ9FQA9shX0IiIBDfoKACKpqs+LiAQ06GOlm4aUnE5uiIhI5wtm0NfFSjfRVF1DLyISzKBvHNGn6hp6EZFABr3XxGr00TQFvYhIIOft9dpK6jwFS0nv7KaIiHS6QI7oozWVVNGDlLB1dlNERDpdIIPeayvZ4xmkhBT0IiKBDHpqK6kik3AomN0TETkYgUxCr62kkh6kqnQjIpJc0JvZdDNba2brzOyuVtbnmtkLZrbczD4ws3EJ6zaZ2QozW2pmizqy8W22t66KPZ5BWKUbEZH2g97MwsBDwHnAGOAqMxvTYrNZwFJ3nwB8E7i/xfoz3H2iuxd2QJvbVxt7MzZVpRsRkaRG9FOBde6+wd3rgKeBi1psMwZ4E8DdPwaGmVn/Dm3pQQjVVVKlEb2ICJBc0A8GtiQ8LoovS7QMuATAzKYCRwND4usceN3MFpvZ9V+suUmK1FNHqi6vFBEhuQ9MtZaW3uLxz4D7zWwpsAJYAjTE153i7sVm1g94w8w+dvcF+z1J7JfA9QBHHXVUks1vgzuOkaLSjYhIUiP6ImBowuMhQHHiBu5e4e4z3X0isRp9PrAxvq44/r0EeIFYKWg/7j7X3QvdvTA/P/9g+9HiYFGihDSiFxEhuaD/EBhpZsPNLA24EngxcQMz6x1fB3AdsMDdK8wsy8xy4ttkAecAKzuu+W2JEsX0gSkREZIo3bh7g5ndBLwGhIFH3X2Vmd0QXz8HGA08YWYRYDVwbXz3/sALZtb4XE+5+6sd342WjY7GSjdhlW5ERJKa1MzdXwFeabFsTsLP7wEjW9lvA1DwBdt48Nw1ohcRiQvkkNfiI3pdXikiEtCgh9hVN5oCQUQkqEHvsTdjNamZiEhAg95UoxcRaRLMoCeK6zp6EREgiEHvsQ/tOuiTsSIiBDLoowBEPaTSjYgIgQz62Ig+iql0IyJCIIM+PqLXpGYiIkCAgx6N6EVEgCAGPQmlG9XoRUQCGPQJpRtNgSAiEuigD5Gq2StFRIIb9A4a0YuIEMigb/zAlK6jFxGBQAZ9/KobCxG/4YmIyBEtgEEfG9Er5EVEYgIY9LERvVnwuiYicigCmIaxET36VKyICBDEoNeIXkSkmeClYWPQ64obEREgkEEfK92ELNzJDRER6RoCGPTxyytVoxcRAQIc9KagFxEBAhz0IV1HLyICBDHoafzAlGr0IiIQxKBv/GSsSjciIkAgg141ehGRRMFLw6YaffC6JiJyKIKXhirdiIg0E7w0VOlGRKSZpNLQzKab2VozW2dmd7WyPtfMXjCz5Wb2gZmNS3bfDqfSjYhIM+2mocWuU3wIOA8YA1xlZmNabDYLWOruE4BvAvcfxL4dqzHow7q8UkQEkhvRTwXWufsGd68DngYuarHNGOBNAHf/GBhmZv2T3LeDNV5HrxG9iAgkF/SDgS0Jj4viyxItAy4BMLOpwNHAkCT37Vga0YuINJNM0Lc2l4C3ePwzINfMlgI3A0uAhiT3jT2J2fVmtsjMFpWWlibRrDZoCgQRkWZSktimCBia8HgIUJy4gbtXADMBLHaz1o3xr8z29k04xlxgLkBhYWGrvwyS0nSDKZVuREQguRH9h8BIMxtuZmnAlcCLiRuYWe/4OoDrgAXx8G933w6n0o2ISDPtjujdvcHMbgJeA8LAo+6+ysxuiK+fA4wGnjCzCLAauPZA+x6erjQ2WLcSFBFJlEzpBnd/BXilxbI5CT+/B4xMdt/DqnFEr9KNiAgQxE/GNhbpNaIXEQGCGPSNtxJU0IuIAAEOepVuRERigpeGTSN6XUcvIgKBDHrV6EVEEgUvDTVNsYhIM8FLw/iIXlMgiIjEBC7o3SOxH0yfjBURgSAGfVTTFIuIJApcGkabRvSB65qIyCEJXBp6tPHNWNXoRUQgiEHvjaUb1ehFRCCIQR+NlW40ohcRiQlc0EcbSzca0YuIAAEMetXoRUSaC17Q68YjIiLNBC4Nm0o3IZVuREQggEG/b0Sv0o2ICAQw6IlqUjMRkUSBS8No43X0CnoRESCAQd90Hb3ejBURAQIZ9PFbCSroRUSAIAa9bjwiItJM4NLQVaMXEWkmcGm4b64bXUcvIgJBDHpvrNHrOnoREQhk0GuaYhGRRAEMer0ZKyKSKHBpuK9GH7iuiYgckuClYeN19Ap6EREggEG/r0YfuK6JiBySwKVh01U3GtGLiABJBr2ZTTeztWa2zszuamV9LzN7ycyWmdkqM5uZsG6Tma0ws6VmtqgjG9+axikQUNCLiACQ0t4GFrtO8SHgbKAI+NDMXnT31Qmb3QisdvcLzSwfWGtmT7p7XXz9Ge6+o6Mb36r4iD6soBcRAZIb0U8F1rn7hnhwPw1c1GIbB3IsdrePbKAcaOjQliZp3xQIuo5eRASSC/rBwJaEx0XxZYkeBEYDxcAK4BZvLJbHfgm8bmaLzez6tp7EzK43s0Vmtqi0tDTpDrTk3jhNsT4ZKyICyQV9a4npLR6fCywFBgETgQfNrGd83SnuPhk4D7jRzE5t7Uncfa67F7p7YX5+fjJtb50urxQRaSaZNCwChiY8HkJs5J5oJvC8x6wDNgKjANy9OP69BHiBWCnosGks3YRUuhERAZIL+g+BkWY23MzSgCuBF1ts8xkwDcDM+gPHAxvMLMvMcuLLs4BzgJUd1fjW6PJKEZHm2r3qxt0bzOwm4DUgDDzq7qvM7Ib4+jnAvcDjZraCWKnnTnffYWYjgBfi9fIU4Cl3f/Uw9SXeYM11IyKSqN2gB3D3V4BXWiybk/BzMbHResv9NgAFX7CNB8WjUaJumqZYRCQueMNed6IYYQW9iAgQwKB3jxLFUM6LiMQELujxKE5IpRsRkbjABb17FEdT3YiINApeHLoTJaQavYhIXACDvrFGr6AXEYEABr1HY0EfUs6LiAABDPrYB6aMsJJeRAQIYNA7Hh/RK+hFRCCAQU9U19GLiCQKXtB7FNeIXkSkSSCDPqoavYhIkwAGveOEVLoREYkLYNBH9WasiEiCwAW9q0YvItJM4IJe0xSLiDQXvKAnNqK3APZMRORQBC4OzXWHKRGRRIEL+n01+s5uiYhI1xC4oG+s0WtELyISE9Cg1x2mREQaBS7oTaUbEZFmUjq7AR3N49MUa0QvIhITuBE9jdMUa0gvIgIEMOgbSzciIhITuKBHQS8i0kwAg95xfSxWRKRJABNRI3oRkUSBC3qLf2BKRERiAhf0xC+vFBGRmOAFPU5UNXoRkSZJJaKZTTeztWa2zszuamV9LzN7ycyWmdkqM5uZ7L4dTiN6EZFm2g16MwsDDwHnAWOAq8xsTIvNbgRWu3sBcDpwn5mlJblvh7L4XDciIhKTTCJOBda5+wZ3rwOeBi5qsY0DOWZmQDZQDjQkuW8Hix7ew4uIdDPJBP1gYEvC46L4skQPAqOBYmAFcIvHJp1JZl8AzOx6M1tkZotKS0uTbH4rdB29iEgzySRiawVvb/H4XGApMAiYCDxoZj2T3De20H2uuxe6e2F+fn4SzWqjsR7FVboREWmSTCIWAUMTHg8hNnJPNBN43mPWARuBUUnu28FcH5gSEUmQTNB/CIw0s+FmlgZcCbzYYpvPgGkAZtYfOB7YkOS+Hco8imuKYhGRJu3OR+/uDWZ2E/AaEAYedfdVZnZDfP0c4F7gcTNbQaxcc6e77wBobd/D05WmFqPLK0VE9knqxiPu/grwSotlcxJ+LgbOSXbfwyk2oleNXkSkUeAS0VSjFxFpJnBBr/noRUSaC1zQGw4q3YiINAleIrrrOnoRkQRJvRnbnRi6vFKkI9XX11NUVERNTU1nN0WAjIwMhgwZQmpqatL7BC7ocV1eKdKRioqKyMnJYdiwYZgGUZ3K3SkrK6OoqIjhw4cnvV/gahyG5roR6Ug1NTX06dNHId8FmBl9+vQ56L+uApeI+mSsSMdTyHcdh3Iughf06MYjIiKJAhf0MQHtlojIIQhcImoKBBE5VA0NDZ3dhMMicFfdxN6MVelG5HD48UurWF1c0aHHHDOoJ/dcOLbd7b72ta+xZcsWampquOWWW7j++ut59dVXmTVrFpFIhL59+/Lmm29SVVXFzTffzKJFizAz7rnnHi699FKys7OpqqoC4Nlnn+Xll1/m8ccf51vf+hZ5eXksWbKEyZMnM2PGDG699Vaqq6vp0aMHjz32GMcffzyRSIQ777yT1157DTPj29/+NmPGjOHBBx/khRdeAOCNN97g4Ycf5vnnn+/Q1+iLClzQh1SjFwmkRx99lLy8PKqrqznhhBO46KKL+Pa3v82CBQsYPnw45eXlANx777306tWLFStWALBz5852j/3JJ58wb948wuEwFRUVLFiwgJSUFObNm8esWbN47rnnmDt3Lhs3bmTJkiWkpKRQXl5Obm4uN954I6WlpeTn5/PYY48xc+bMw/o6HIrABT2uKRBEDpdkRt6HywMPPNA0ct6yZQtz587l1FNPbbqePC8vD4B58+bx9NNPN+2Xm5vb7rEvv/xywuEwALt37+aaa67h008/xcyor69vOu4NN9xASkpKs+f7xje+wR/+8AdmzpzJe++9xxNPPNFBPe44gQt6XUcvEjxvv/028+bN47333iMzM5PTTz+dgoIC1q5du9+27t7qJYiJy1peh56VldX08913380ZZ5zBCy+8wKZNmzj99NMPeNyZM2dy4YUXkpGRweWXX970i6ArCVwi6vJKkeDZvXs3ubm5ZGZm8vHHH/O3v/2N2tpa3nnnHTZu3AjQVLo555xzePDBB5v2bSzd9O/fnzVr1hCNRpv+MmjruQYPHgzA448/3rT8nHPOYc6cOU1v2DY+36BBgxg0aBA/+clP+Na3vtVhfe5IwQt6d9CbsSKBMn36dBoaGpgwYQJ33303J510Evn5+cydO5dLLrmEgoICZsyYAcAPf/hDdu7cybhx4ygoKGD+/PkA/OxnP+OCCy7gzDPPZODAgW0+1x133MH3v/99TjnlFCKRSNPy6667jqOOOooJEyZQUFDAU0891bTu6quvZujQoYwZM+YwvQJfjLl7Z7dhP4WFhb5o0aJD2rf8x8NYkf0PnPZ/nmp/YxFp15o1axg9enRnN6NLu+mmm5g0aRLXXnvt3+X5WjsnZrbY3Qtb277rFZO+oNgdpgL3h4qIdFFTpkwhKyuL++67r7Ob0qYABn1UpRsR+btZvHhxZzehXYEb+sbuMKWgFxFpFLyg13X0IiLNBCsR555OT6oIWrdERL6IYCVin2N5O/wPLOl1Zme3RESkywjWm7GX/pa7179FYWZeZ7dERKTLCNaIHohGIaQ3Y0WOaNnZ2Z3dhC4lWCN6YvNRhJTzIofH/9wFn6/o2GMOGA/n/axjj9lFNDQ0dIm5b4I3oneN6EWC5s477+TXv/510+PZs2fz4x//mGnTpjF58mTGjx/Pn//856SOVVVV1eZ+TzzxRNMUB9/4xjcA2L59OxdffDEFBQUUFBSwcOFCNm3axLhx45r2+8UvfsHs2bMBOP3005k1axannXYa999/Py+99BInnngikyZN4qyzzmL79u1N7Zg5cybjx49nwoQJPPfcc/zud7/jtttuazruI488wu23337Ir1sTd+9yX1OmTPFDVfiTN/yu55Yd8v4i0tzq1as7uwn+0Ucf+amnntr0ePTo0b5582bfvXu3u7uXlpb6Mccc49Fo1N3ds7Ky2jxWfX19q/utXLnSjzvuOC8tLXV397KyMnd3v+KKK/yXv/ylu7s3NDT4rl27fOPGjT527NimY/785z/3e+65x93dTzvtNP/Od77TtK68vLypXY888ojffvvt7u5+xx13+C233NJsu6qqKh8xYoTX1dW5u/vJJ5/sy5cv368PrZ0TYJG3kamd/zdFB3N3jehFAmbSpEmUlJRQXFxMaWkpubm5DBw4kNtuu40FCxYQCoXYunUr27dvZ8CAAQc8lrsza9as/fZ76623uOyyy+jbty+wb775t956q2mO+XA4TK9evdq9mUnjBGsARUVFzJgxg23btlFXV9c0f35b8+afeeaZvPzyy4wePZr6+nrGjx9/kK/W/gIX9CrdiATTZZddxrPPPsvnn3/OlVdeyZNPPklpaSmLFy8mNTWVYcOG7TfPfGva2s/bmG++NSkpKUSj0abHB5rf/uabb+b222/nq1/9Km+//XZTiaet57vuuuv46U9/yqhRozrsblVJ1ejNbLqZrTWzdWZ2Vyvrv2dmS+NfK80sYmZ58XWbzGxFfN2hTUl5EKJ6M1YkkK688kqefvppnn32WS677DJ2795Nv379SE1NZf78+WzevDmp47S137Rp0/iv//ovysrKgH3zzU+bNo2HH34YgEgkQkVFBf3796ekpISysjJqa2t5+eWXD/h8jfPb//73v29a3ta8+SeeeCJbtmzhqaee4qqrrkr25TmgdoPezMLAQ8B5wBjgKjNrNumyu//c3Se6+0Tg+8A77l6esMkZ8fWtTqHZUS781V/Ytbc+6d/KItJ9jB07lsrKSgYPHszAgQO5+uqrWbRoEYWFhTz55JOMGjUqqeO0td/YsWP5wQ9+wGmnnUZBQUHTm6D3338/8+fPZ/z48UyZMoVVq1aRmprKj370I0488UQuuOCCAz737Nmzufzyy/nyl7/cVBaCtufNB7jiiis45ZRTkroNYjLanY/ezE4GZrv7ufHH3wdw939tY/ungPnu/kj88Sag0N13JNuoQ52P/tanl1Afca798nAmH9UxL5DIkU7z0f/9XXDBBdx2221Mmzat1fWHYz76wcCWhMdFwImtbWhmmcB04KaExQ68bmYO/Mbd57ax7/XA9QBHHXVUEs3a339cOemQ9hMR6Qp27drF1KlTKSgoaDPkD0UyQd9aHaStPwMuBP7aomxzirsXm1k/4A0z+9jdF+x3wNgvgLkQG9En0S4RkTatWLGi6Vr4Runp6bz//vud1KL29e7dm08++aTDj5tM0BcBQxMeDwGK29j2SuCPiQvcvTj+vcTMXgCmAvsFvYh0XQdzRUpXMX78eJYuXdrZzehw7ZXbW5PMVTcfAiPNbLiZpREL8xdbbmRmvYDTgD8nLMsys5zGn4FzgJUH3UoR6TQZGRmUlZUdUsBIx3J3ysrKyMjIOKj92h3Ru3uDmd0EvAaEgUfdfZWZ3RBfPye+6cXA6+6+J2H3/sAL8ZFACvCUu796UC0UkU41ZMgQioqKKC0t7eymCLFfvEOGDDmofdq96qYzHOpVNyIiR6oDXXUTuEnNRESkOQW9iEjAKehFRAKuS9bozawUSG7iiv31BZL+FG4Xp750PUHpB6gvXdWh9uVod89vbUWXDPovwswWHe45df5e1JeuJyj9APWlqzocfVHpRkQk4BT0IiIBF8Sgb3XStG5Kfel6gtIPUF+6qg7vS+Bq9CIi0lwQR/QiIpJAQS8iEnCBCfr27mvb1bV2b10zyzOzN8zs0/j3LnnbLDN71MxKzGxlwrI2225m34+fp7Vmdm7ntLp1bfRltpltTbgv8vkJ67pyX4aa2XwzW2Nmq8zslvjybnVuDtCPbndezCzDzD4ws2Xxvvw4vvzwnhN37/ZfxGbVXA+MANKAZcCYzm7XQfZhE9C3xbJ/B+6K/3wX8G+d3c422n4qMBlY2V7bid13eBmQDgyPn7dwZ/ehnb7MBv65lW27el8GApPjP+cAn8Tb3K3OzQH60e3OC7EbOWXHf04F3gdOOtznJCgj+qnAOnff4O51wNPARZ3cpo5wEdB42/jfA1/rvKa0zWN3DCtvsbittl8EPO3ute6+EVhH7Px1CW30pS1dvS/b3P2j+M+VwBpitwbtVufmAP1oS5fsB4DHVMUfpsa/nMN8ToIS9K3d1/ZA/xC6osZ76y6O3z8XoL+7b4PYP3agX6e17uC11fbueq5uMrPl8dJO45/V3aYvZjYMmERsBNltz02LfkA3PC9mFjazpUAJ8Ia7H/ZzEpSgP5j72nZVp7j7ZOA84EYzO7WzG3SYdMdz9TBwDDAR2AbcF1/eLfpiZtnAc8Ct7l5xoE1bWdZl+tNKP7rleXH3iLtPJHZb1qlmNu4Am3dIX4IS9AdzX9suyRPurQs03lt3u5kNBIh/L+m8Fh60ttre7c6Vu2+P/+eMAo+w70/nLt8XM0slFo5Puvvz8cXd7ty01o/ufF4A3H0X8DYwncN8ToIS9End17arOsC9dV8Erolvdg0J9+PtBtpq+4vAlWaWbmbDgZHAB53QvqQ1/geMu5h99z3u0n2x2D08fwescff/m7CqW52btvrRHc+LmeWbWe/4zz2As4CPOdznpLPfhe7Ad7PPJ/Zu/HrgB53dnoNs+whi76wvA1Y1th/oA7wJfBr/ntfZbW2j/X8k9qdzPbERyLUHajvwg/h5Wguc19ntT6Iv/wmsAJbH/+MN7CZ9+RKxP/OXA0vjX+d3t3NzgH50u/MCTACWxNu8EvhRfPlhPSeaAkFEJOCCUroREZE2KOhFRAJOQS8iEnAKehGRgFPQi4gEnIJeRCTgFPQiIgH3/wHF+iUljmnSmwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['accuracy','val_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.012471022542852622, 0.9976923]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(scaled_X_test,y_test,verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ready Model for Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = len(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=12,activation='relu'))\n",
    "\n",
    "# Last layer for multi-class classification of 2 colors\n",
    "model.add(Dense(units=2,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6497 samples\n",
      "Epoch 1/300\n",
      "6497/6497 [==============================] - 0s 64us/sample - loss: 0.5383 - accuracy: 0.7487\n",
      "Epoch 2/300\n",
      "6497/6497 [==============================] - 0s 32us/sample - loss: 0.3496 - accuracy: 0.8370\n",
      "Epoch 3/300\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.1937 - accuracy: 0.9577\n",
      "Epoch 4/300\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.1237 - accuracy: 0.9769\n",
      "Epoch 5/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0935 - accuracy: 0.9809\n",
      "Epoch 6/300\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0783 - accuracy: 0.9826\n",
      "Epoch 7/300\n",
      "6497/6497 [==============================] - 0s 31us/sample - loss: 0.0689 - accuracy: 0.9840\n",
      "Epoch 8/300\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0627 - accuracy: 0.9852\n",
      "Epoch 9/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0584 - accuracy: 0.9861\n",
      "Epoch 10/300\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0551 - accuracy: 0.9861\n",
      "Epoch 11/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0528 - accuracy: 0.9866\n",
      "Epoch 12/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0507 - accuracy: 0.9875\n",
      "Epoch 13/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0493 - accuracy: 0.9885\n",
      "Epoch 14/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0474 - accuracy: 0.9883\n",
      "Epoch 15/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0463 - accuracy: 0.9891\n",
      "Epoch 16/300\n",
      "6497/6497 [==============================] - 0s 27us/sample - loss: 0.0450 - accuracy: 0.9889\n",
      "Epoch 17/300\n",
      "6497/6497 [==============================] - 0s 31us/sample - loss: 0.0441 - accuracy: 0.9886\n",
      "Epoch 18/300\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0432 - accuracy: 0.9888\n",
      "Epoch 19/300\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0422 - accuracy: 0.9900\n",
      "Epoch 20/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0416 - accuracy: 0.9897\n",
      "Epoch 21/300\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0409 - accuracy: 0.9901\n",
      "Epoch 22/300\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0401 - accuracy: 0.9908\n",
      "Epoch 23/300\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0394 - accuracy: 0.9906\n",
      "Epoch 24/300\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0393 - accuracy: 0.9903\n",
      "Epoch 25/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0384 - accuracy: 0.9912\n",
      "Epoch 26/300\n",
      "6497/6497 [==============================] - 0s 31us/sample - loss: 0.0378 - accuracy: 0.9906\n",
      "Epoch 27/300\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0372 - accuracy: 0.9914\n",
      "Epoch 28/300\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0369 - accuracy: 0.9920\n",
      "Epoch 29/300\n",
      "6497/6497 [==============================] - 0s 27us/sample - loss: 0.0365 - accuracy: 0.9917\n",
      "Epoch 30/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0361 - accuracy: 0.9918\n",
      "Epoch 31/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0356 - accuracy: 0.9915\n",
      "Epoch 32/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0354 - accuracy: 0.9918\n",
      "Epoch 33/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0353 - accuracy: 0.9914\n",
      "Epoch 34/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0344 - accuracy: 0.9918\n",
      "Epoch 35/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0342 - accuracy: 0.9915\n",
      "Epoch 36/300\n",
      "6497/6497 [==============================] - 0s 27us/sample - loss: 0.0338 - accuracy: 0.9914\n",
      "Epoch 37/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0336 - accuracy: 0.9922\n",
      "Epoch 38/300\n",
      "6497/6497 [==============================] - 0s 27us/sample - loss: 0.0336 - accuracy: 0.9920\n",
      "Epoch 39/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0330 - accuracy: 0.9918\n",
      "Epoch 40/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0329 - accuracy: 0.9917\n",
      "Epoch 41/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0325 - accuracy: 0.9926\n",
      "Epoch 42/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0321 - accuracy: 0.9928\n",
      "Epoch 43/300\n",
      "6497/6497 [==============================] - 0s 27us/sample - loss: 0.0321 - accuracy: 0.9928\n",
      "Epoch 44/300\n",
      "6497/6497 [==============================] - 0s 31us/sample - loss: 0.0317 - accuracy: 0.9923\n",
      "Epoch 45/300\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0315 - accuracy: 0.9926\n",
      "Epoch 46/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0312 - accuracy: 0.9926\n",
      "Epoch 47/300\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0313 - accuracy: 0.9925\n",
      "Epoch 48/300\n",
      "6497/6497 [==============================] - 0s 32us/sample - loss: 0.0309 - accuracy: 0.9928\n",
      "Epoch 49/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0307 - accuracy: 0.9925\n",
      "Epoch 50/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0306 - accuracy: 0.9926\n",
      "Epoch 51/300\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0297 - accuracy: 0.9934\n",
      "Epoch 52/300\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0300 - accuracy: 0.9925\n",
      "Epoch 53/300\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0299 - accuracy: 0.9931\n",
      "Epoch 54/300\n",
      "6497/6497 [==============================] - 0s 27us/sample - loss: 0.0296 - accuracy: 0.9931\n",
      "Epoch 55/300\n",
      "6497/6497 [==============================] - 0s 32us/sample - loss: 0.0295 - accuracy: 0.9931\n",
      "Epoch 56/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0292 - accuracy: 0.9940\n",
      "Epoch 57/300\n",
      "6497/6497 [==============================] - 0s 27us/sample - loss: 0.0290 - accuracy: 0.9932\n",
      "Epoch 58/300\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0287 - accuracy: 0.9934\n",
      "Epoch 59/300\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0286 - accuracy: 0.9937\n",
      "Epoch 60/300\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0284 - accuracy: 0.9937\n",
      "Epoch 61/300\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0284 - accuracy: 0.9934\n",
      "Epoch 62/300\n",
      "6497/6497 [==============================] - ETA: 0s - loss: 0.0271 - accuracy: 0.99 - 0s 30us/sample - loss: 0.0282 - accuracy: 0.9931\n",
      "Epoch 63/300\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0283 - accuracy: 0.9935\n",
      "Epoch 64/300\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0280 - accuracy: 0.9929\n",
      "Epoch 65/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0276 - accuracy: 0.9943\n",
      "Epoch 66/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0277 - accuracy: 0.9935\n",
      "Epoch 67/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0273 - accuracy: 0.9937\n",
      "Epoch 68/300\n",
      "6497/6497 [==============================] - 0s 31us/sample - loss: 0.0271 - accuracy: 0.9940\n",
      "Epoch 69/300\n",
      "6497/6497 [==============================] - 0s 31us/sample - loss: 0.0274 - accuracy: 0.9932\n",
      "Epoch 70/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0271 - accuracy: 0.9937\n",
      "Epoch 71/300\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0269 - accuracy: 0.9940\n",
      "Epoch 72/300\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0267 - accuracy: 0.9942\n",
      "Epoch 73/300\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0265 - accuracy: 0.9942\n",
      "Epoch 74/300\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0265 - accuracy: 0.9943\n",
      "Epoch 75/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0263 - accuracy: 0.9940\n",
      "Epoch 76/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0262 - accuracy: 0.9946\n",
      "Epoch 77/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0261 - accuracy: 0.9943\n",
      "Epoch 78/300\n",
      "6497/6497 [==============================] - 0s 27us/sample - loss: 0.0260 - accuracy: 0.9943\n",
      "Epoch 79/300\n",
      "6497/6497 [==============================] - 0s 27us/sample - loss: 0.0259 - accuracy: 0.9943\n",
      "Epoch 80/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0257 - accuracy: 0.9943\n",
      "Epoch 81/300\n",
      "6497/6497 [==============================] - 0s 27us/sample - loss: 0.0255 - accuracy: 0.9943\n",
      "Epoch 82/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0256 - accuracy: 0.9943\n",
      "Epoch 83/300\n",
      "6497/6497 [==============================] - 0s 27us/sample - loss: 0.0253 - accuracy: 0.9942\n",
      "Epoch 84/300\n",
      "6497/6497 [==============================] - 0s 27us/sample - loss: 0.0254 - accuracy: 0.9945\n",
      "Epoch 85/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0250 - accuracy: 0.9948\n",
      "Epoch 86/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0250 - accuracy: 0.9946\n",
      "Epoch 87/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0246 - accuracy: 0.9943\n",
      "Epoch 88/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0250 - accuracy: 0.9946\n",
      "Epoch 89/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0247 - accuracy: 0.9948\n",
      "Epoch 90/300\n",
      "6497/6497 [==============================] - 0s 27us/sample - loss: 0.0243 - accuracy: 0.9945\n",
      "Epoch 91/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0244 - accuracy: 0.9946\n",
      "Epoch 92/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0239 - accuracy: 0.9948\n",
      "Epoch 93/300\n",
      "6497/6497 [==============================] - 0s 31us/sample - loss: 0.0238 - accuracy: 0.9949\n",
      "Epoch 94/300\n",
      "6497/6497 [==============================] - 0s 27us/sample - loss: 0.0243 - accuracy: 0.9948\n",
      "Epoch 95/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0238 - accuracy: 0.9949\n",
      "Epoch 96/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0238 - accuracy: 0.9951\n",
      "Epoch 97/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0237 - accuracy: 0.9951\n",
      "Epoch 98/300\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0234 - accuracy: 0.9949\n",
      "Epoch 99/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0235 - accuracy: 0.9949\n",
      "Epoch 100/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0231 - accuracy: 0.9948\n",
      "Epoch 101/300\n",
      "6497/6497 [==============================] - 0s 27us/sample - loss: 0.0231 - accuracy: 0.9948\n",
      "Epoch 102/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0231 - accuracy: 0.9949\n",
      "Epoch 103/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0229 - accuracy: 0.9949\n",
      "Epoch 104/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0232 - accuracy: 0.9948\n",
      "Epoch 105/300\n",
      "6497/6497 [==============================] - 0s 27us/sample - loss: 0.0224 - accuracy: 0.9949\n",
      "Epoch 106/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0226 - accuracy: 0.9957\n",
      "Epoch 107/300\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0224 - accuracy: 0.9951\n",
      "Epoch 108/300\n",
      "6497/6497 [==============================] - 0s 27us/sample - loss: 0.0223 - accuracy: 0.9949\n",
      "Epoch 109/300\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0223 - accuracy: 0.9952\n",
      "Epoch 110/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0225 - accuracy: 0.9951\n",
      "Epoch 111/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0219 - accuracy: 0.9951\n",
      "Epoch 112/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0222 - accuracy: 0.9952\n",
      "Epoch 113/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0217 - accuracy: 0.9951\n",
      "Epoch 114/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0217 - accuracy: 0.9952\n",
      "Epoch 115/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0217 - accuracy: 0.9949\n",
      "Epoch 116/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0215 - accuracy: 0.9952\n",
      "Epoch 117/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0214 - accuracy: 0.9954\n",
      "Epoch 118/300\n",
      "6497/6497 [==============================] - 0s 27us/sample - loss: 0.0216 - accuracy: 0.9951\n",
      "Epoch 119/300\n",
      "6497/6497 [==============================] - 0s 27us/sample - loss: 0.0214 - accuracy: 0.9954\n",
      "Epoch 120/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0209 - accuracy: 0.9952\n",
      "Epoch 121/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0212 - accuracy: 0.9951\n",
      "Epoch 122/300\n",
      "6497/6497 [==============================] - 0s 27us/sample - loss: 0.0211 - accuracy: 0.9952\n",
      "Epoch 123/300\n",
      "6497/6497 [==============================] - 0s 27us/sample - loss: 0.0207 - accuracy: 0.9954\n",
      "Epoch 124/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0205 - accuracy: 0.9954\n",
      "Epoch 125/300\n",
      "6497/6497 [==============================] - 0s 27us/sample - loss: 0.0208 - accuracy: 0.9955\n",
      "Epoch 126/300\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0205 - accuracy: 0.9952\n",
      "Epoch 127/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0203 - accuracy: 0.9960\n",
      "Epoch 128/300\n",
      "6497/6497 [==============================] - 0s 27us/sample - loss: 0.0204 - accuracy: 0.9954\n",
      "Epoch 129/300\n",
      "6497/6497 [==============================] - ETA: 0s - loss: 0.0208 - accuracy: 0.99 - 0s 27us/sample - loss: 0.0203 - accuracy: 0.9957\n",
      "Epoch 130/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0203 - accuracy: 0.9962\n",
      "Epoch 131/300\n",
      "6497/6497 [==============================] - 0s 27us/sample - loss: 0.0201 - accuracy: 0.9955\n",
      "Epoch 132/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0200 - accuracy: 0.9955\n",
      "Epoch 133/300\n",
      "6497/6497 [==============================] - 0s 27us/sample - loss: 0.0200 - accuracy: 0.9957\n",
      "Epoch 134/300\n",
      "6497/6497 [==============================] - 0s 27us/sample - loss: 0.0201 - accuracy: 0.9957\n",
      "Epoch 135/300\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0198 - accuracy: 0.9955\n",
      "Epoch 136/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0195 - accuracy: 0.9958\n",
      "Epoch 137/300\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0198 - accuracy: 0.9958\n",
      "Epoch 138/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0195 - accuracy: 0.9955\n",
      "Epoch 139/300\n",
      "6497/6497 [==============================] - 0s 27us/sample - loss: 0.0193 - accuracy: 0.9962\n",
      "Epoch 140/300\n",
      "6497/6497 [==============================] - 0s 27us/sample - loss: 0.0196 - accuracy: 0.9958\n",
      "Epoch 141/300\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0192 - accuracy: 0.9958\n",
      "Epoch 142/300\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0193 - accuracy: 0.9958\n",
      "Epoch 143/300\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0192 - accuracy: 0.9957\n",
      "Epoch 144/300\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0192 - accuracy: 0.9958\n",
      "Epoch 145/300\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0190 - accuracy: 0.9958\n",
      "Epoch 146/300\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0189 - accuracy: 0.9962\n",
      "Epoch 147/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0189 - accuracy: 0.9957\n",
      "Epoch 148/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0189 - accuracy: 0.9955\n",
      "Epoch 149/300\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0189 - accuracy: 0.9962\n",
      "Epoch 150/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0188 - accuracy: 0.9960\n",
      "Epoch 151/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0187 - accuracy: 0.9958\n",
      "Epoch 152/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0187 - accuracy: 0.9958\n",
      "Epoch 153/300\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0186 - accuracy: 0.9960\n",
      "Epoch 154/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0218 - accuracy: 0.9949\n",
      "Epoch 155/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0183 - accuracy: 0.9962\n",
      "Epoch 156/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0182 - accuracy: 0.9962\n",
      "Epoch 157/300\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0180 - accuracy: 0.9958\n",
      "Epoch 158/300\n",
      "6497/6497 [==============================] - 0s 27us/sample - loss: 0.0181 - accuracy: 0.9960\n",
      "Epoch 159/300\n",
      "6497/6497 [==============================] - 0s 27us/sample - loss: 0.0182 - accuracy: 0.9963\n",
      "Epoch 160/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0181 - accuracy: 0.9962\n",
      "Epoch 161/300\n",
      "6497/6497 [==============================] - 0s 27us/sample - loss: 0.0181 - accuracy: 0.9960\n",
      "Epoch 162/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0179 - accuracy: 0.9960\n",
      "Epoch 163/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0190 - accuracy: 0.9962\n",
      "Epoch 164/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0179 - accuracy: 0.9963\n",
      "Epoch 165/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0179 - accuracy: 0.9963\n",
      "Epoch 166/300\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0180 - accuracy: 0.9963\n",
      "Epoch 167/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0179 - accuracy: 0.9960\n",
      "Epoch 168/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0179 - accuracy: 0.9960\n",
      "Epoch 169/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0177 - accuracy: 0.9962\n",
      "Epoch 170/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0177 - accuracy: 0.9960\n",
      "Epoch 171/300\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0175 - accuracy: 0.9962\n",
      "Epoch 172/300\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0177 - accuracy: 0.9963\n",
      "Epoch 173/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0173 - accuracy: 0.9962\n",
      "Epoch 174/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0175 - accuracy: 0.9963\n",
      "Epoch 175/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0177 - accuracy: 0.9963\n",
      "Epoch 176/300\n",
      "6497/6497 [==============================] - 0s 27us/sample - loss: 0.0173 - accuracy: 0.9963\n",
      "Epoch 177/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0173 - accuracy: 0.9962\n",
      "Epoch 178/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0173 - accuracy: 0.9960\n",
      "Epoch 179/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0173 - accuracy: 0.9962\n",
      "Epoch 180/300\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0170 - accuracy: 0.9965\n",
      "Epoch 181/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0173 - accuracy: 0.9962\n",
      "Epoch 182/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0171 - accuracy: 0.9962\n",
      "Epoch 183/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0170 - accuracy: 0.9966\n",
      "Epoch 184/300\n",
      "6497/6497 [==============================] - 0s 27us/sample - loss: 0.0169 - accuracy: 0.9963\n",
      "Epoch 185/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0169 - accuracy: 0.9965\n",
      "Epoch 186/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0165 - accuracy: 0.9965\n",
      "Epoch 187/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0168 - accuracy: 0.9966\n",
      "Epoch 188/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0168 - accuracy: 0.9965\n",
      "Epoch 189/300\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0166 - accuracy: 0.9966\n",
      "Epoch 190/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0167 - accuracy: 0.9968\n",
      "Epoch 191/300\n",
      "6497/6497 [==============================] - 0s 27us/sample - loss: 0.0166 - accuracy: 0.9963\n",
      "Epoch 192/300\n",
      "6497/6497 [==============================] - 0s 27us/sample - loss: 0.0163 - accuracy: 0.9965\n",
      "Epoch 193/300\n",
      "6497/6497 [==============================] - 0s 27us/sample - loss: 0.0165 - accuracy: 0.9965\n",
      "Epoch 194/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0163 - accuracy: 0.9963\n",
      "Epoch 195/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0164 - accuracy: 0.9965\n",
      "Epoch 196/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0160 - accuracy: 0.9966\n",
      "Epoch 197/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0161 - accuracy: 0.9965\n",
      "Epoch 198/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0163 - accuracy: 0.9963\n",
      "Epoch 199/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0177 - accuracy: 0.9963\n",
      "Epoch 200/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0160 - accuracy: 0.9966\n",
      "Epoch 201/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0159 - accuracy: 0.9962\n",
      "Epoch 202/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0157 - accuracy: 0.9965\n",
      "Epoch 203/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0158 - accuracy: 0.9966\n",
      "Epoch 204/300\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0158 - accuracy: 0.9963\n",
      "Epoch 205/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0157 - accuracy: 0.9966\n",
      "Epoch 206/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0158 - accuracy: 0.9965\n",
      "Epoch 207/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0158 - accuracy: 0.9965\n",
      "Epoch 208/300\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0157 - accuracy: 0.9966\n",
      "Epoch 209/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0156 - accuracy: 0.9963\n",
      "Epoch 210/300\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0154 - accuracy: 0.9963\n",
      "Epoch 211/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0156 - accuracy: 0.9966\n",
      "Epoch 212/300\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0154 - accuracy: 0.9968\n",
      "Epoch 213/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0155 - accuracy: 0.9962\n",
      "Epoch 214/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0155 - accuracy: 0.9966\n",
      "Epoch 215/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0153 - accuracy: 0.9965\n",
      "Epoch 216/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0153 - accuracy: 0.9966\n",
      "Epoch 217/300\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0154 - accuracy: 0.9966\n",
      "Epoch 218/300\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0151 - accuracy: 0.9966\n",
      "Epoch 219/300\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0151 - accuracy: 0.9965\n",
      "Epoch 220/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0148 - accuracy: 0.9966\n",
      "Epoch 221/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0152 - accuracy: 0.9966\n",
      "Epoch 222/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0152 - accuracy: 0.9966\n",
      "Epoch 223/300\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0151 - accuracy: 0.9966\n",
      "Epoch 224/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0181 - accuracy: 0.9955\n",
      "Epoch 225/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0149 - accuracy: 0.9969\n",
      "Epoch 226/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0148 - accuracy: 0.9966\n",
      "Epoch 227/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0148 - accuracy: 0.9966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 228/300\n",
      "6497/6497 [==============================] - 0s 27us/sample - loss: 0.0148 - accuracy: 0.9966\n",
      "Epoch 229/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0150 - accuracy: 0.9966\n",
      "Epoch 230/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0147 - accuracy: 0.9966\n",
      "Epoch 231/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0146 - accuracy: 0.9969\n",
      "Epoch 232/300\n",
      "6497/6497 [==============================] - 0s 27us/sample - loss: 0.0147 - accuracy: 0.9966\n",
      "Epoch 233/300\n",
      "6497/6497 [==============================] - 0s 27us/sample - loss: 0.0148 - accuracy: 0.9966\n",
      "Epoch 234/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0146 - accuracy: 0.9966\n",
      "Epoch 235/300\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0147 - accuracy: 0.9966\n",
      "Epoch 236/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0143 - accuracy: 0.9971\n",
      "Epoch 237/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0146 - accuracy: 0.9968\n",
      "Epoch 238/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0146 - accuracy: 0.9966\n",
      "Epoch 239/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0145 - accuracy: 0.9968\n",
      "Epoch 240/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0145 - accuracy: 0.9965\n",
      "Epoch 241/300\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0143 - accuracy: 0.9969\n",
      "Epoch 242/300\n",
      "6497/6497 [==============================] - 0s 27us/sample - loss: 0.0144 - accuracy: 0.9969\n",
      "Epoch 243/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0146 - accuracy: 0.9965\n",
      "Epoch 244/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0143 - accuracy: 0.9966\n",
      "Epoch 245/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0143 - accuracy: 0.9966\n",
      "Epoch 246/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0144 - accuracy: 0.9966\n",
      "Epoch 247/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0143 - accuracy: 0.9969\n",
      "Epoch 248/300\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0140 - accuracy: 0.9968\n",
      "Epoch 249/300\n",
      "6497/6497 [==============================] - 0s 27us/sample - loss: 0.0146 - accuracy: 0.9968\n",
      "Epoch 250/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0142 - accuracy: 0.9966\n",
      "Epoch 251/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0140 - accuracy: 0.9966\n",
      "Epoch 252/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0141 - accuracy: 0.9965\n",
      "Epoch 253/300\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0142 - accuracy: 0.9969\n",
      "Epoch 254/300\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0141 - accuracy: 0.9966\n",
      "Epoch 255/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0141 - accuracy: 0.9966\n",
      "Epoch 256/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0138 - accuracy: 0.9968\n",
      "Epoch 257/300\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0141 - accuracy: 0.9968\n",
      "Epoch 258/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0140 - accuracy: 0.9968\n",
      "Epoch 259/300\n",
      "6497/6497 [==============================] - 0s 31us/sample - loss: 0.0138 - accuracy: 0.9968\n",
      "Epoch 260/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0140 - accuracy: 0.9963\n",
      "Epoch 261/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0138 - accuracy: 0.9969\n",
      "Epoch 262/300\n",
      "6497/6497 [==============================] - 0s 30us/sample - loss: 0.0140 - accuracy: 0.9968\n",
      "Epoch 263/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0140 - accuracy: 0.9966\n",
      "Epoch 264/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0137 - accuracy: 0.9968\n",
      "Epoch 265/300\n",
      "6497/6497 [==============================] - 0s 31us/sample - loss: 0.0139 - accuracy: 0.9966\n",
      "Epoch 266/300\n",
      "6497/6497 [==============================] - 0s 27us/sample - loss: 0.0137 - accuracy: 0.9969\n",
      "Epoch 267/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0137 - accuracy: 0.9971\n",
      "Epoch 268/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0135 - accuracy: 0.9968\n",
      "Epoch 269/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0138 - accuracy: 0.9969\n",
      "Epoch 270/300\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0137 - accuracy: 0.9971\n",
      "Epoch 271/300\n",
      "6497/6497 [==============================] - 0s 27us/sample - loss: 0.0136 - accuracy: 0.9969\n",
      "Epoch 272/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0135 - accuracy: 0.9968\n",
      "Epoch 273/300\n",
      "6497/6497 [==============================] - 0s 27us/sample - loss: 0.0137 - accuracy: 0.9968\n",
      "Epoch 274/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0135 - accuracy: 0.9971\n",
      "Epoch 275/300\n",
      "6497/6497 [==============================] - 0s 27us/sample - loss: 0.0136 - accuracy: 0.9969\n",
      "Epoch 276/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0137 - accuracy: 0.9966s - loss: 0.0152 - accuracy: 0.99\n",
      "Epoch 277/300\n",
      "6497/6497 [==============================] - 0s 27us/sample - loss: 0.0136 - accuracy: 0.9969\n",
      "Epoch 278/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0135 - accuracy: 0.9966\n",
      "Epoch 279/300\n",
      "6497/6497 [==============================] - 0s 27us/sample - loss: 0.0134 - accuracy: 0.9969\n",
      "Epoch 280/300\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0135 - accuracy: 0.9965\n",
      "Epoch 281/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0134 - accuracy: 0.9971\n",
      "Epoch 282/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0135 - accuracy: 0.9965\n",
      "Epoch 283/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0133 - accuracy: 0.9969\n",
      "Epoch 284/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0134 - accuracy: 0.9966\n",
      "Epoch 285/300\n",
      "6497/6497 [==============================] - 0s 27us/sample - loss: 0.0133 - accuracy: 0.9969\n",
      "Epoch 286/300\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0133 - accuracy: 0.9968\n",
      "Epoch 287/300\n",
      "6497/6497 [==============================] - 0s 27us/sample - loss: 0.0137 - accuracy: 0.9966\n",
      "Epoch 288/300\n",
      "6497/6497 [==============================] - 0s 27us/sample - loss: 0.0131 - accuracy: 0.9971\n",
      "Epoch 289/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0133 - accuracy: 0.9969\n",
      "Epoch 290/300\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0131 - accuracy: 0.9969\n",
      "Epoch 291/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0133 - accuracy: 0.9971\n",
      "Epoch 292/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0131 - accuracy: 0.9969\n",
      "Epoch 293/300\n",
      "6497/6497 [==============================] - 0s 29us/sample - loss: 0.0130 - accuracy: 0.9972\n",
      "Epoch 294/300\n",
      "6497/6497 [==============================] - 0s 27us/sample - loss: 0.0131 - accuracy: 0.9971\n",
      "Epoch 295/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0129 - accuracy: 0.9968\n",
      "Epoch 296/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0130 - accuracy: 0.9966\n",
      "Epoch 297/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0132 - accuracy: 0.9969\n",
      "Epoch 298/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0130 - accuracy: 0.9971\n",
      "Epoch 299/300\n",
      "6497/6497 [==============================] - 0s 27us/sample - loss: 0.0130 - accuracy: 0.9968\n",
      "Epoch 300/300\n",
      "6497/6497 [==============================] - 0s 28us/sample - loss: 0.0130 - accuracy: 0.9968\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26b29071390>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_X,y,epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"final_wine_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wine_scaler.pkl']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(scaler,'wine_scaler.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting a Single New Wine Color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Sequential models without an `input_shape` passed to the first layer cannot reload their optimizer state. As a result, your model isstarting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "wine_model = load_model(\"final_wine_model.h5\")\n",
    "wine_scaler = joblib.load(\"wine_scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density   pH  sulphates  \\\n",
       "0                 45.0                 170.0    1.001  3.0       0.45   \n",
       "\n",
       "   alcohol  quality  color  \n",
       "0      8.8        6  white  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# white wine attributes for testing\n",
    "\n",
    "wine_example = {'fixed_acidity':7.0,\n",
    "                 'volatile_acidity':0.27,\n",
    "                 'citric_acid':0.36,\n",
    "                 'residual_sugar':20.7,\n",
    "                 'chlorides':0.045,\n",
    "                 'free_sulfur_dioxide':45.0,\n",
    "                 'total_sulfur_dioxide':170.0,\n",
    "                 'density':1.001,\n",
    "                 'pH':3.0,\n",
    "                 'sulphates':0.45,\n",
    "                 'alcohol':8.8,\n",
    "                 'quality':6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['fixed_acidity', 'volatile_acidity', 'citric_acid', 'residual_sugar', 'chlorides', 'free_sulfur_dioxide', 'total_sulfur_dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_example.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['red', 'white'], dtype='<U5')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_prediction(model,scaler,sample_json):\n",
    "    \n",
    "    # For larger data features, you should probably write a for loop\n",
    "    # That builds out this array for you\n",
    "    \n",
    "    f_a = sample_json['fixed_acidity']\n",
    "    v_a = sample_json['volatile_acidity']\n",
    "    c_a = sample_json['citric_acid']\n",
    "    r_s = sample_json['residual_sugar']\n",
    "    chl = sample_json['chlorides']\n",
    "    f_s_d = sample_json['free_sulfur_dioxide']\n",
    "    t_s_d = sample_json['total_sulfur_dioxide']\n",
    "    den = sample_json['density']\n",
    "    ph = sample_json['pH']\n",
    "    sul = sample_json['sulphates']\n",
    "    alc = sample_json['alcohol']\n",
    "    qua = sample_json['quality']\n",
    "    \n",
    "    wine = [[f_a,v_a,c_a,r_s,chl,f_s_d,t_s_d,den,ph,sul,alc,qua]]\n",
    "    \n",
    "    wine = scaler.transform(wine)\n",
    "    \n",
    "    classes = np.array(['red', 'white'])\n",
    "    \n",
    "    class_ind = model.predict_classes(wine)\n",
    "    \n",
    "    return classes[class_ind][0]\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'white'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction based on \"wine example\" white wine inputs should predict \"white\"\n",
    "\n",
    "return_prediction(wine_model,wine_scaler,wine_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE FOR DEPLOYMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Sequential models without an `input_shape` passed to the first layer cannot reload their optimizer state. As a result, your model isstarting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "\n",
    "\n",
    "wine_model = load_model(\"final_wine_model.h5\")\n",
    "wine_scaler = joblib.load(\"wine_scaler.pkl\")\n",
    "\n",
    "\n",
    "def return_prediction(model,scaler,sample_json):\n",
    "    \n",
    "    # For larger data features, you should probably write a for loop\n",
    "    # That builds out this array for you\n",
    "    f_a = sample_json['fixed_acidity']\n",
    "    v_a = sample_json['volatile_acidity']\n",
    "    c_a = sample_json['citric_acid']\n",
    "    r_s = sample_json['residual_sugar']\n",
    "    chl = sample_json['chlorides']\n",
    "    f_s_d = sample_json['free_sulfur_dioxide']\n",
    "    t_s_d = sample_json['total_sulfur_dioxide']\n",
    "    den = sample_json['density']\n",
    "    ph = sample_json['pH']\n",
    "    sul = sample_json['sulphates']\n",
    "    alc = sample_json['alcohol']\n",
    "    qua = sample_json['quality']\n",
    "    \n",
    "    wine = [[f_a,v_a,c_a,r_s,chl,f_s_d,t_s_d,den,ph,sul,alc,qua]]\n",
    "    \n",
    "    wine = scaler.transform(wine)\n",
    "    \n",
    "    classes = np.array(['red', 'white'])\n",
    "    \n",
    "    class_ind = model.predict_classes(wine)\n",
    "    \n",
    "    return classes[class_ind][0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonAdv]",
   "language": "python",
   "name": "conda-env-PythonAdv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
